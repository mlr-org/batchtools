[{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"cluster-functions","dir":"Articles","previous_headings":"Setup","what":"Cluster Functions","title":"batchtools","text":"communication batch system managed via -called cluster functions. created constructor makeClusterFunctions defines jobs submitted system. Furthermore, may provide functions list queued/running jobs kill jobs. Usually start scratch can just use one cluster functions ship package: Interactive Cluster Functions (default): docs, implementation Multicore Cluster Functions: docs, implementation Socket Cluster Functions: docs, implementation Makeshift SSH cluster: docs, implementation Docker Swarm: docs, implementation IBM Spectrum Load Sharing Facility (LSF): docs, implementation OpenLava: docs, implementation Univa Grid Engine / Oracle Grid Engine (OGE) / Sun Grid Engine (SGE): docs, implementation Slurm: docs, implementation TORQUE/OpenPBS: docs, implementation use package socket cluster functions, call respective constructor makeClusterFunctionsSocket(): make selection permanent registry, save Registry saveRegistry(). make cluster function selection permanent specific system across R sessions new Registries, can set configuration file (see ). trouble debugging cluster functions, can enable debug mode extra output. , install debugme package set environment variable DEBUGME batchtools load batchtools package:","code":"reg = makeRegistry(NA) reg$cluster.functions = makeClusterFunctionsSocket(2) Sys.setenv(DEBUGME = \"batchtools\") library(batchtools)"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"template-files","dir":"Articles","previous_headings":"Setup","what":"Template Files","title":"batchtools","text":"Many cluster functions require template file argument. templates used communicate scheduler contain placeholders evaluate arbitrary R expressions. Internally, brew package used purpose. exemplary template files can found . great help expand collection cover exotic configurations. , please send template via mail open new pull request. Note variables defined JobCollection can used inside template. need pass extra variables, can set via argument resources submitJobs(). flexibility comes templating sufficient, can still construct custom cluster function implementation using provided constructor.","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"configuration-file","dir":"Articles","previous_headings":"Setup","what":"Configuration File","title":"batchtools","text":"configuration file can used set system specific options. default location depends operating system (see Registry), first time setup can put one current working directory (reported getwd()). order set cluster function implementation, generate file following content: configuration file parsed whenever create load Registry. sourced inside registry advantage can () access parameters passed makeRegistry (b) can also directly change . Lets say always want working directory home directory always want load checkmate package nodes, can just append lines: See documentation Registry complete list supported configuration options.","code":"cluster.functions = makeClusterFunctionsInteractive() work.dir = \"~\" packages = union(packages, \"checkmate\")"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"migration-from-batchjobsbatchexperiments","dir":"Articles","previous_headings":"","what":"Migration from BatchJobs/Batchexperiments","title":"batchtools","text":"development BatchJobs BatchExperiments discontinued following reasons: Maintainability: packages BatchJobs BatchExperiments tightly connected makes maintaining difficult. Changes synchronized tested current CRAN versions compatibility. Furthermore, BatchExperiments violates CRAN policies calling internal functions BatchJobs. Data base issues: Although invested weeks mitigate issues locks SQLite data base file system (staged queries, file system timeouts, …), BatchJobs kept working unreliable systems high latency specific file systems. made BatchJobs unusable many users. BatchJobs BatchExperiments remain CRAN, new features unlikely ported back.","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"internal-changes","dir":"Articles","previous_headings":"Migration from BatchJobs/Batchexperiments","what":"Internal Changes","title":"batchtools","text":"batchtools use SQLite anymore. Instead, information stored directly registry using data.tables acting -memory database. side effect, many operations much faster. Nodes access registry. submitJobs() stores temporary object type JobCollection file system holds information necessary execute chunk jobs via doJobCollection() node. avoids file system locks job accesses one file exclusively. ClusterFunctionsMulticore now uses parallel package multicore execution. ClusterFunctionsSSH can still used emulate scheduler-like system respects work load local machine. Setting hostname \"localhost\" just strips ssh command issued.","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"interface-changes","dir":"Articles","previous_headings":"Migration from BatchJobs/Batchexperiments","what":"Interface Changes","title":"batchtools","text":"batchtools remembers last created loaded Registry sets default registry. way, need pass registry around anymore. need work multiple registries simultaneously hand, can still explicitly passing registries functions. functions now return data.table keyed job.id. way, return values can joined together easily efficient (see help page examples). building blocks problem renamed static dynamic intuitive data fun. Thus, algorithm function formal arguments job, data instance. function makeDesign removed. Parameters can defined just passing data.frame data.table addExperiments. exhaustive designs, use data.table::CJ().","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"template-changes","dir":"Articles","previous_headings":"Migration from BatchJobs/Batchexperiments","what":"Template changes","title":"batchtools","text":"scheduler directly execute command: intermediate R source file like BatchJobs. * information stored object JobCollection can accessed brewing template. * Extra variables may passed via argument resoures submitJobs.","code":"Rscript -e 'batchtools::doJobCollection(<filename>)'"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"new-features","dir":"Articles","previous_headings":"Migration from BatchJobs/Batchexperiments","what":"New features","title":"batchtools","text":"Support Docker Swarm via ClusterFunctionsDocker. Jobs can now tagged untagged provide easy way group . resources like number CPUs now optionally passed parallelMap. eases nested parallelization, e.g. use multicore parallelization slave just setting resource master. See submitJobs() example. ClusterFunctions now flexible general can define hook functions called certain events. ClusterFunctionsDocker example use case implements housekeeping routine. routine called every time job get submitted scheduler (case: Docker Swarm) via hook pre.submit every time directly registry synchronized jobs stored file system via hook post.sync. new features covered NEWS.","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"porting-to-batchtools","dir":"Articles","previous_headings":"Migration from BatchJobs/Batchexperiments","what":"Porting to batchtools","title":"batchtools","text":"following table assists porting batchtools mapping BatchJobs/BatchExperiments functions counterparts batchtools. table cover functions () used internally BatchJobs (b) functions renamed.","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"example-1-approximation-of-pi","dir":"Articles","previous_headings":"","what":"Example 1: Approximation of \\(\\pi\\)","title":"batchtools","text":"get first insight usage batchtools, start exemplary Monte Carlo simulation approximate \\(\\pi\\). background information, see Wikipedia. First, -called registry object created, defines directory relevant information, files results computational jobs stored. two different types registry objects: First, regular Registry use example. Second, ExperimentRegistry provides alternative way define computational jobs thereby tailored broad range large scale computer experiments. , use temporary registry stored temp directory system gets automatically deleted close R session. permanent registry, set file.dir valid path. can reused later, e.g., login system , calling function loadRegistry(file.dir). registry object created loaded, stored active R session default. Therefore argument reg ignored functions calls example, assuming correct registry set default. get current default registry, getDefaultRegistry can used. switch another registry, use setDefaultRegistry(). First, create function samples \\(n\\) points \\((x_i, y_i)\\) whereas \\(x_i\\) \\(y_i\\) distributed uniformly, .e. \\(x_i, y_i \\sim \\mathcal{U}(0,1)\\). Next, distance origin \\((0, 0)\\) calculated fraction points unit circle (\\(d \\leq 1\\)) returned. now parallelize piApprox() batchtools: create 10 jobs, MC simulation \\(10^5\\) jobs. use batchMap() define jobs (note yet start calculation): length vector list defines many different jobs created, elements used arguments function. function batchMap(fun, ...) works analogously Map(f, ...) base package. overview jobs IDs can retrieved getJobTable() returns data.frame relevant information: Note unique job ID assigned job. IDs can used restrict operations subsets jobs. actually start calculation, call submitJobs(). registry selected job IDs can taken arguments well arbitrary list resource requirements, handled cluster back end. example, cap execution time (-called walltime) maximum memory requirements set. progress submitted jobs can checked getStatus(). resulting output includes number jobs registry, many submitted, started execute batch system, currently running, successfully completed, terminated due R exception. jobs successfully terminated, can load results master. can done simple fashion using either loadResult(), returns single result exactly form calculated mapping, using reduceResults(), version Reduce() base package registry objects. absolutely sure function works, can take shortcut use batchtools lapply fashion using btlapply(). function creates temporary registry (may also pass one ), calls batchMap(), wait jobs terminate waitForJobs() uses reduceResultsList() return results.","code":"reg = makeRegistry(file.dir = NA, seed = 1) piApprox = function(n) {   nums = matrix(runif(2 * n), ncol = 2)   d = sqrt(nums[, 1]^2 + nums[, 2]^2)   4 * mean(d <= 1) } set.seed(42) piApprox(1000) ## [1] 3.156 batchMap(fun = piApprox, n = rep(1e5, 10)) ## Adding 10 jobs ... names(getJobTable()) ##  [1] \"job.id\"       \"submitted\"    \"started\"      \"done\"         \"error\"        ##  [6] \"mem.used\"     \"batch.id\"     \"log.file\"     \"job.hash\"     \"job.name\"     ## [11] \"time.queued\"  \"time.running\" \"job.pars\"     \"resources\"    \"tags\" submitJobs(resources = list(walltime = 3600, memory = 1024)) ## Submitting 10 jobs in 10 chunks using cluster functions 'Interactive' ... getStatus() ## Status for 10 jobs at 2025-05-22 14:40:13: ##   Submitted    : 10 (100.0%) ##   -- Queued    :  0 (  0.0%) ##   -- Started   : 10 (100.0%) ##   ---- Running :  0 (  0.0%) ##   ---- Done    : 10 (100.0%) ##   ---- Error   :  0 (  0.0%) ##   ---- Expired :  0 (  0.0%) waitForJobs() ## [1] TRUE mean(sapply(1:10, loadResult)) ## [1] 3.140652 reduceResults(function(x, y) x + y) / 10 ## [1] 3.140652 res = btlapply(rep(1e5, 10), piApprox) mean(unlist(res)) ## [1] 3.14124"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"example-2-machine-learning","dir":"Articles","previous_headings":"","what":"Example 2: Machine Learning","title":"batchtools","text":"stick rather simple, unrealistic example explain functionalities: Applying two classification learners famous iris data set (Anderson 1935), vary hyperparameters evaluate effect classification performance. First, create registry, central meta-data object records technical details setup experiments. use ExperimentRegistry job definition split creating problems algorithms. See paper BatchJobs BatchExperiments detailed explanation. , use temporary registry make default registry.","code":"library(batchtools) reg = makeExperimentRegistry(file.dir = NA, seed = 1)"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"problems-and-algorithms","dir":"Articles","previous_headings":"Example 2: Machine Learning","what":"Problems and Algorithms","title":"batchtools","text":"adding problem registry, can define data certain computational jobs shall work. can matrix, data frame array always stays subsequent experiments. can also dynamic nature, e.g., subsamples dataset random numbers drawn probability distribution . Therefore function addProblem() accepts static parts data argument, passed argument fun generates (possibly stochastic) problem instance. data, R object can used. data given, generated instance data. argument fun function arguments data job (optionally arbitrary parameters). argument job object type Job holds additional information job. want split iris data set training set test set. example use use subsampling just randomly takes fraction observations training set. define problem function returns indices respective training test set split 100 * ratio% observations test set: addProblem() files problem file system problem gets recorded registry. function call evaluated later stage workers. process, data part loaded passed function. Note set problem seed synchronize experiments sense resampled training test sets used algorithm comparison distinct replication. algorithms jobs added registry similar manner. using addAlgorithm(), identifier well algorithm apply required arguments. algorithm must given function arguments job, data instance. arbitrary arguments (e.g., hyperparameters strategy parameters) may defined analogously function addProblem. objects passed function via job data , via instance return value evaluated problem function passed. algorithm can return R object automatically stored file system later retrieval. Firstly, create algorithm applies support vector machine: Secondly, random forest classification trees: algorithms return confusion matrix predictions test set, later used calculate misclassification rate. Note using ... argument wrapper definitions allows us circumvent naming specific design parameters now. advantage later want extend set algorithm parameters experiment. algorithms get recorded registry corresponding functions stored file system. Defined problems algorithms can queried : flow define experiments summarized following figure:","code":"subsample = function(data, job, ratio, ...) {   n = nrow(data)   train = sample(n, floor(n * ratio))   test = setdiff(seq_len(n), train)   list(test = test, train = train) } data(\"iris\", package = \"datasets\") addProblem(name = \"iris\", data = iris, fun = subsample, seed = 42) ## Adding problem 'iris' svm.wrapper = function(data, job, instance, ...) {   library(\"e1071\")   mod = svm(Species ~ ., data = data[instance$train, ], ...)   pred = predict(mod, newdata = data[instance$test, ], type = \"class\")   table(data$Species[instance$test], pred) } addAlgorithm(name = \"svm\", fun = svm.wrapper) ## Adding algorithm 'svm' forest.wrapper = function(data, job, instance, ...) {   library(\"ranger\")   mod = ranger(Species ~ ., data = data[instance$train, ], write.forest = TRUE)   pred = predict(mod, data = data[instance$test, ])   table(data$Species[instance$test], pred$predictions) } addAlgorithm(name = \"forest\", fun = forest.wrapper) ## Adding algorithm 'forest' reg$problems ## [1] \"iris\" reg$algorithms ## [1] \"svm\"    \"forest\""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"creating-jobs","dir":"Articles","previous_headings":"Example 2: Machine Learning","what":"Creating jobs","title":"batchtools","text":"addExperiments() used parametrize jobs thereby define computational jobs. , pass named lists parameters addExperiments(). elements respective list (one problems one algorithms) must named problem algorithm refer . data frames contain parameter constellations problem algorithm function columns must names target arguments. problem design algorithm design combined addExperiments(), combination parameter sets two designs defines distinct job. often jobs computed can determined argument repls. jobs now available registry individual job ID . function summarizeExperiments() returns table gives quick overview defined experiments.","code":"# problem design: try two values for the ratio parameter pdes = list(iris = data.table(ratio = c(0.67, 0.9)))  # algorithm design: try combinations of kernel and epsilon exhaustively, # try different number of trees for the forest ades = list(   svm = CJ(kernel = c(\"linear\", \"polynomial\", \"radial\"), epsilon = c(0.01, 0.1)),   forest = data.table(ntree = c(100, 500, 1000)) )  addExperiments(pdes, ades, repls = 5) ## Adding 60 experiments ('iris'[2] x 'svm'[6] x repls[5]) ... ## Adding 30 experiments ('iris'[2] x 'forest'[3] x repls[5]) ... summarizeExperiments() ##    problem algorithm .count ##     <char>    <char>  <int> ## 1:    iris       svm     60 ## 2:    iris    forest     30 summarizeExperiments(by = c(\"problem\", \"algorithm\", \"ratio\")) ##    problem algorithm ratio .count ##     <char>    <char> <num>  <int> ## 1:    iris       svm  0.67     30 ## 2:    iris       svm  0.90     30 ## 3:    iris    forest  0.67     15 ## 4:    iris    forest  0.90     15"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"before-submitting","dir":"Articles","previous_headings":"Example 2: Machine Learning","what":"Before Submitting","title":"batchtools","text":"submitting jobs batch system, encourage test algorithm individually. sometimes want submit subset experiments jobs vastly differ runtime. Another reoccurring task collection results subset experiments. use cases, findExperiments() can employed conveniently select particular subset jobs. returns IDs experiments match given criteria. selection can depend substring matches problem algorithm IDs using prob.name algo.name, respectively. can also pass R expressions, evaluated problem parameter setting (prob.pars) algorithm parameter setting (algo.pars). expression expected evaluate Boolean value. Furthermore, can restrict experiments specific replication numbers. illustrate findExperiments(), select two experiments, one support vector machine random forest parameter ntree = 1000. selected experiment IDs passed testJob. something goes wrong, batchtools comes bunch useful debugging utilities (see separate vignette error handling). everything turns fine, can proceed calculation.","code":"id1 = head(findExperiments(algo.name = \"svm\"), 1) print(id1) ## Key: <job.id> ##    job.id ##     <int> ## 1:      1 id2 = head(findExperiments(algo.name = \"forest\", algo.pars = (ntree == 1000)), 1) print(id2) ## Key: <job.id> ##    job.id ##     <int> ## 1:     71 testJob(id = id1) ## ### [bt]: Generating problem instance for problem 'iris' ... ## ### [bt]: Applying algorithm 'svm' on problem 'iris' for job 1 (seed = 2) ... ##             pred ##              setosa versicolor virginica ##   setosa         13          0         0 ##   versicolor      0         17         0 ##   virginica       0          1        19 testJob(id = id2) ## ### [bt]: Generating problem instance for problem 'iris' ... ## ### [bt]: Applying algorithm 'forest' on problem 'iris' for job 71 (seed = 72) ... ##              ##              setosa versicolor virginica ##   setosa         13          0         0 ##   versicolor      0         16         1 ##   virginica       0          1        19"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"submitting-and-collecting-results","dir":"Articles","previous_headings":"Example 2: Machine Learning","what":"Submitting and Collecting Results","title":"batchtools","text":"submit jobs, call submitJobs() wait jobs terminate using waitForJobs(). jobs finished, results can collected reduceResultsDataTable() directly extract mean misclassification error: Next, merge results table table job parameters using one join helpers provided batchtools (, use inner join): now aggregate results group-wise. can use data.table, base::aggregate(), dplyr package purpose. , use data.table subset table jobs ratio 0.67 group algorithm algorithm hyperparameters:","code":"submitJobs() ## Submitting 90 jobs in 90 chunks using cluster functions 'Interactive' ... waitForJobs() ## [1] TRUE reduce = function(res) list(mce = (sum(res) - sum(diag(res))) / sum(res)) results = unwrap(reduceResultsDataTable(fun = reduce)) head(results) ## Key: <job.id> ##    job.id   mce ##     <int> <num> ## 1:      1  0.02 ## 2:      2  0.00 ## 3:      3  0.04 ## 4:      4  0.06 ## 5:      5  0.02 ## 6:      6  0.02 pars = unwrap(getJobPars()) tab = ijoin(pars, results) head(tab) ## Key: <job.id> ##    job.id problem algorithm ratio kernel epsilon ntree   mce ##     <int>  <char>    <char> <num> <char>   <num> <num> <num> ## 1:      1    iris       svm  0.67 linear    0.01    NA  0.02 ## 2:      2    iris       svm  0.67 linear    0.01    NA  0.00 ## 3:      3    iris       svm  0.67 linear    0.01    NA  0.04 ## 4:      4    iris       svm  0.67 linear    0.01    NA  0.06 ## 5:      5    iris       svm  0.67 linear    0.01    NA  0.02 ## 6:      6    iris       svm  0.67 linear    0.10    NA  0.02 tab[ratio == 0.67, list(mmce = mean(mce)),   by = c(\"algorithm\", \"kernel\", \"epsilon\", \"ntree\")] ##    algorithm     kernel epsilon ntree  mmce ##       <char>     <char>   <num> <num> <num> ## 1:       svm     linear    0.01    NA 0.028 ## 2:       svm     linear    0.10    NA 0.028 ## 3:       svm polynomial    0.01    NA 0.096 ## 4:       svm polynomial    0.10    NA 0.096 ## 5:       svm     radial    0.01    NA 0.044 ## 6:       svm     radial    0.10    NA 0.044 ## 7:    forest       <NA>      NA   100 0.044 ## 8:    forest       <NA>      NA   500 0.048 ## 9:    forest       <NA>      NA  1000 0.044"},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"example-error-handling","dir":"Articles","previous_headings":"","what":"Example: Error Handling","title":"batchtools","text":"large scale experiment many things can go wrong. cluster might outage, jobs may run resource limits crash, subtle bugs code triggered error condition might arise. situations important quickly determine went wrong recompute minimal number required jobs. Therefore, submit anything use testJob() catch errors easy spot raised many jobs. external set, function runs job without side effects independent R process local machine via Rscript similar slave, redirects output process R console, loads job result returns . set external, job executed currently running R session, drawback might unable catch missing variable declarations missing package dependencies. way illustration small example. First, create temporary registry. Ten jobs created, one trow warning two raise exception. Now jobs defined, can test jobs independently: case, testing job ID = 1 provides appropriate result testing job ID = 2 leads error: ignore error , just assume everything looks fine submit jobs. submitted jobs suspect something going wrong, first thing run getStatus() display summary current state system. status message shows two jobs executed successfully. get IDs jobs failed due error can use findErrors() retrieve actual error message, can use getErrorMessages(). want peek R log file job see context error can use showLog() opens pager use getLog() get log character vector: can also grep messages (output suppressed vignette technical reasons):","code":"library(batchtools) reg = makeRegistry(file.dir = NA, seed = 1) flakeyFunction <- function(value) {   if (value == 5) warning(\"Just a simple warning\")   if (value %in% c(2, 9)) stop(\"Ooops.\")   value^2 } batchMap(flakeyFunction, 1:10) ## Adding 10 jobs ... testJob(id = 1) ## ### [bt]: Setting seed to 2 ... ## [1] 1 as.character(try(testJob(id = 2))) ## ### [bt]: Setting seed to 3 ... ## Error in (function (value)  : Ooops. ## [1] \"Error in (function (value)  : Ooops.\\n\" submitJobs() ## Submitting 10 jobs in 10 chunks using cluster functions 'Interactive' ... ## Error in (function (value)  : Ooops. ## Warning in (function (value) : Just a simple warning ## Error in (function (value)  : Ooops. waitForJobs() ## [1] FALSE getStatus() ## Status for 10 jobs at 2025-05-22 14:40:18: ##   Submitted    : 10 (100.0%) ##   -- Queued    :  0 (  0.0%) ##   -- Started   : 10 (100.0%) ##   ---- Running :  0 (  0.0%) ##   ---- Done    :  8 ( 80.0%) ##   ---- Error   :  2 ( 20.0%) ##   ---- Expired :  0 (  0.0%) findErrors() ## Key: <job.id> ##    job.id ##     <int> ## 1:      2 ## 2:      9 getErrorMessages() ## Key: <job.id> ##    job.id terminated  error                              message ##     <int>     <lgcl> <lgcl>                               <char> ## 1:      2       TRUE   TRUE Error in (function (value)  : Ooops. ## 2:      9       TRUE   TRUE Error in (function (value)  : Ooops. tail(getLog(id = 9)) ## [1] \"### [bt]: Memory measurement disabled\"                            ## [2] \"### [bt]: Starting job [batchtools job.id=9]\"                     ## [3] \"### [bt]: Setting seed to 10 ...\"                                 ## [4] \"\"                                                                 ## [5] \"### [bt]: Job terminated with an exception [batchtools job.id=9]\" ## [6] \"### [bt]: Calculation finished!\" grepLogs(pattern = \"simple\", ignore.case = TRUE)"},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"on-the-local-system","dir":"Articles","previous_headings":"Workflow","what":"On the Local System","title":"batchtools","text":"Create Registry makeRegistry() (makeExperimentRegistry()) load existing file system loadRegistry(). Define computational jobs batchMap() batchReduce() used makeRegistry() define addAlgorithm(), addProblem() addExperiments() started makeExperimentRegistry(). advised test jobs testJob() interactive session testJob(external = TRUE) separate R process. Note can add additional jobs using ExperimentRegistry. required, query data base job ids depending status, parameters tags (see findJobs()). returned tables can easily combined set-like fashion data base verbs: union (ojoin() outer join), intersect (ijoin() inner join), difference (ajoin() anti join). Submit jobs submitJobs(). can specify job resources . thousands fast terminating jobs, want chunk() first. jobs already terminated, can estimate runtimes estimateRuntimes() chunk jobs heterogeneous groups lpt() binpack(). Monitor jobs. getStatus() gives summarizing overview. Use showLog() grepLogs() investigate log file. Run jobs currently running session testJob() get traceback(). Collect (partial) results. loadResult() retrieves single result file system. reduceResults() mimics Reduce() allows apply function many files iterative fashion. reduceResultsList() reduceResultsDataTable() collect results list data.table, respectively.","code":""},{"path":"https://batchtools.mlr-org.com/dev/articles/batchtools.html","id":"on-multiple-systems","dir":"Articles","previous_headings":"Workflow","what":"On Multiple Systems","title":"batchtools","text":"users develop prototype experiments desktop box preferred IDE later deploy large computing cluster. can done prototyping locally (testJob() submit subsets via submitJobs()). deploy cluster, just copy file directory (reported reg$file.dir) remote system. Next, log cluster (typically via ssh), cd copied directory call loadRegistry(\"<file.dir..remote\">, \"<work.dir..remote>\", writeable = TRUE). function () source local configuration file can talk cluster (verify checking output reg$cluster.functions) (b) adjust paths new system argument update.paths set. loading Registry, advised test jobs testJob() submitting submitJobs(resources = list()) (remember now need set resources!). jobs finished, file.dir can copied back (merge previous directory!) loaded loadRegistry(). approach totally viable long general rules followed: Make sure packages installed. Package versions can synchronized across machines checkpoint packrat. Test jobs remote system prior submit ensure paths resolved correctly. Make sure set cluster functions configuration file, stick one backend long jobs running. status can monitored remote system (obvious reasons). Partial results can inspected remote system local system. latter, need copy complete file.dir first. Overwriting/merging directories advised may lead inconsistencies added removed experiments remote. merge, use rsync option --delete. Load registry locally loadRegistry() collect results. copy back forth. Avoid accessing file.dir multiple sessions simultaneously. includes accessing registry via mount! Simultaneous access may lead inconsistencies missing results.","code":""},{"path":"https://batchtools.mlr-org.com/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michel Lang. Maintainer, author. Bernd Bischl. Author. Dirk Surmann. Contributor.","code":""},{"path":"https://batchtools.mlr-org.com/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Michel Lang, Bernd Bischl, Dirk Surmann (2017). batchtools: Tools R work batch systems. Journal Open Source Software, 2(10). URL https://doi.org/10.21105/joss.00135. Bernd Bischl, Michel Lang, Olaf Mersmann, Joerg Rahnenfuehrer, Claus Weihs (2015). BatchJobs BatchExperiments: Abstraction Mechanisms Using R Batch Environments. Journal Statistical Software, 64(11), 1-25. URL https://www.jstatsoft.org/v64/i11/.","code":"@Article{,   title = {batchtools: Tools for R to work on batch systems},   author = {Michel Lang and Bernd Bischl and Dirk Surmann},   journal = {The Journal of Open Source Software},   year = {2017},   month = {feb},   number = {10},   doi = {10.21105/joss.00135},   url = {https://doi.org/10.21105/joss.00135}, } @Article{,   title = {{BatchJobs} and {BatchExperiments}: Abstraction Mechanisms for Using {R} in Batch Environments},   author = {Bernd Bischl and Michel Lang and Olaf Mersmann and J{\\\"o}rg Rahnenf{\\\"u}hrer and Claus Weihs},   journal = {Journal of Statistical Software},   year = {2015},   volume = {64},   number = {11},   pages = {1--25},   doi = {10.18637/jss.v064.i11},   url = {https://www.jstatsoft.org/v64/i11/}, }"},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"batchtools","dir":"","previous_headings":"","what":"Tools for Computation on Batch Systems","title":"Tools for Computation on Batch Systems","text":"successor packages BatchJobs BatchExperiments, batchtools provides parallel implementation Map high performance computing systems managed schedulers like Slurm, Sun Grid Engine, OpenLava, TORQUE/OpenPBS, Load Sharing Facility (LSF) Docker Swarm (see setup section vignette). Main features: * Convenience: relevant batch system operations (submitting, listing, killing) either handled internally abstracted via simple R functions * Portability: well-defined interface, source independent underlying batch system - prototype locally, deploy high performance cluster * Reproducibility: Every computational part associated seed stored data base ensures reproducibility even underlying batch system changes * Abstraction: code layers algorithms, experiment definitions execution cleanly separated allow write readable maintainable code manage large scale computer experiments","code":""},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Computation on Batch Systems","text":"Install stable version CRAN: {R} install.packages(\"batchtools\") development version, use devtools: {R} devtools::install_github(\"mllg/batchtools\") Next, need setup batchtools HPC (run sequentially otherwise). See vignette instructions.","code":""},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"why-batchtools","dir":"","previous_headings":"","what":"Why batchtools?","title":"Tools for Computation on Batch Systems","text":"development BatchJobs BatchExperiments discontinued following reasons: Maintainability: packages BatchJobs BatchExperiments tightly connected makes maintenance difficult. Changes synchronized tested current CRAN versions compatibility. Furthermore, BatchExperiments violates CRAN policies calling internal functions BatchJobs. Data base issues: Although invested weeks mitigate issues locks SQLite data base file system (staged queries, file system timeouts, …), BatchJobs kept working unreliable systems high latency certain conditions. made BatchJobs unusable many users. BatchJobs BatchExperiments remain CRAN, new features unlikely ported back. vignette contains section comparing packages.","code":""},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"Tools for Computation on Batch Systems","text":"NEWS Function reference Vignette JOSS Paper: Short paper batchtools. Please cite use batchtools. Paper BatchJobs/BatchExperiments: described concept still holds batchtools examples work analogously (see vignette differences packages).","code":""},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Tools for Computation on Batch Systems","text":"Please cite JOSS paper using following BibTeX entry:","code":"@article{,   doi = {10.21105/joss.00135},   url = {https://doi.org/10.21105/joss.00135},   year  = {2017},   month = {feb},   publisher = {The Open Journal},   volume = {2},   number = {10},   author = {Michel Lang and Bernd Bischl and Dirk Surmann},   title = {batchtools: Tools for R to work on batch systems},   journal = {The Journal of Open Source Software} }"},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"related-software","dir":"","previous_headings":"","what":"Related Software","title":"Tools for Computation on Batch Systems","text":"High Performance Computing Task View lists relevant packages scientific computing R. clustermq similar approach also supports multiple schedulers. Uses ZeroMQ network protocol communication, shines millions fast jobs. batch assists splitting submitting jobs LSF MOSIX clusters. flowr supports LSF, Slurm, TORQUE Moab provides scatter-gather approach define computational jobs. future.batchtools implements batchtools backend future. doFuture together future.batchtools connects batchtools foreach. drake uses graphs define computational jobs. batchtools used backend via future.batchtools.","code":""},{"path":"https://batchtools.mlr-org.com/dev/index.html","id":"contributing-to-batchtools","dir":"","previous_headings":"","what":"Contributing to batchtools","title":"Tools for Computation on Batch Systems","text":"R package licensed LGPL-3. encounter problems using software (lack documentation, misleading wrong documentation, unexpected behaviour, bugs, …) just want suggest features, please open issue issue tracker. Pull requests welcome included discretion author. customized template file (larger) computing site, please share : fork repository, place template inst/templates send pull request.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobCollection.html","id":null,"dir":"Reference","previous_headings":"","what":"JobCollection Constructor — makeJobCollection","title":"JobCollection Constructor — makeJobCollection","text":"makeJobCollection takes multiple job ids creates object class “JobCollection” holds necessary information calculation doJobCollection. implemented environment following variables: file.dir file.dir Registry. work.dir: work.dir Registry. job.hash Unique identifier job. Used create names file system. jobs data.table holding individual job information. See examples. log.file Location designated log file job. resources: Named list specified computational resources. uri Location job description file (saved link[base]{saveRDS} file system. seed integer(1) Seed Registry. packages character required packages load via require. namespaces codecharacter required packages load via requireNamespace. source character list files source execution. load character list files load execution. array.var character(1) array environment variable specified cluster functions. array.jobs logical(1) signaling jobs submitted using chunks..arrayjobs. ClusterFunctions uses template, brew executed environment collection. Thus variables available inside job can used template.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobCollection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"JobCollection Constructor — makeJobCollection","text":"","code":"makeJobCollection(ids = NULL, resources = list(), reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/JobCollection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"JobCollection Constructor — makeJobCollection","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. resources [list] Named list resources. Default list(). reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobCollection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"JobCollection Constructor — makeJobCollection","text":"[JobCollection].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/JobCollection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"JobCollection Constructor — makeJobCollection","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE, packages = \"methods\") #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(identity, 1:5, reg = tmp) #> Adding 5 jobs ...  # resources are usually set in submitJobs() jc = makeJobCollection(1:3, resources = list(foo = \"bar\"), reg = tmp) ls(jc) #>  [1] \"array.jobs\" \"array.var\"  \"compress\"   \"file.dir\"   \"job.hash\"   #>  [6] \"job.name\"   \"jobs\"       \"load\"       \"log.file\"   \"namespaces\" #> [11] \"packages\"   \"resources\"  \"seed\"       \"source\"     \"uri\"        #> [16] \"work.dir\"   jc$resources #> $foo #> [1] \"bar\" #>"},{"path":"https://batchtools.mlr-org.com/dev/reference/JobExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Jobs and Experiments — makeJob","title":"Jobs and Experiments — makeJob","text":"Jobs Experiments abstract objects hold information necessary execute single computational job Registry ExperimentRegistry, respectively. can created using constructor makeJob takes single job id. Jobs Experiments passed reduce functions like reduceResults. Furthermore, Experiments can used functions Problem Algorithm. Jobs Experiments hold information: job.id Job ID integer. pars Job parameters named list.    ExperimentRegistry, parameters divided sublists “prob.pars” “algo.pars”. seed Seed set via doJobCollection scalar integer. resources Computational resources set job named list. external.dir Path directory created exclusively job. can store external files .    Directory persistent multiple restarts job can cleaned calling resetJobs. fun Job : User function passed batchMap. prob.name Experiments : Problem id. algo.name Experiments : Algorithm id. problem Experiments : Problem. instance Experiments : Problem instance. algorithm Experiments : Algorithm. repl Experiments : Replication number. Note slots “pars”, “fun”, “algorithm” “problem” lazy-load required files file system construct object first access. realizations cached slots except “instance” (might stochastic). Jobs Experiments can executed manually execJob.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jobs and Experiments — makeJob","text":"","code":"makeJob(id, reader = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/JobExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jobs and Experiments — makeJob","text":"id [integer(1) data.table] Single integer specify job data.table column job.id exactly one row. reader [RDSReader | NULL] Reader object retrieve files. Used internally cache reading file system. default (NULL) make use caching. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobExperiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jobs and Experiments — makeJob","text":"[Job | Experiment].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobExperiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jobs and Experiments — makeJob","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(function(x, y) x + y, x = 1:2, more.args = list(y = 99), reg = tmp) #> Adding 2 jobs ... submitJobs(resources = list(foo = \"bar\"), reg = tmp) #> Submitting 2 jobs in 2 chunks using cluster functions 'Interactive' ... job = makeJob(1, reg = tmp) print(job) #> <Job> #>   Inherits from: <BaseJob> #>   Public: #>     external.dir: active binding #>     file.dir: /tmp/batchtools-example/reg #>     fun: active binding #>     id: 1 #>     initialize: function (file.dir, reader, id, job.pars, seed, resources)  #>     job.id: active binding #>     job.pars: list #>     pars: active binding #>     reader: RDSReader, R6 #>     resources: list #>     seed: 15284  # Get the parameters: job$pars #> $x #> [1] 1 #>  #> $y #> [1] 99 #>   # Get the job resources: job$resources #> $foo #> [1] \"bar\" #>   # Execute the job locally: execJob(job) #> ### [bt]: Setting seed to 15284 ... #> [1] 100"},{"path":"https://batchtools.mlr-org.com/dev/reference/JobNames.html","id":null,"dir":"Reference","previous_headings":"","what":"Set and Retrieve Job Names — JobNames","title":"Set and Retrieve Job Names — JobNames","text":"Set custom names jobs. passed template ‘job.name’. custom name set (job names chunk missing), job hash used job name. Individual job names can accessed via jobs$job.name.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobNames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set and Retrieve Job Names — JobNames","text":"","code":"setJobNames(ids = NULL, names, reg = getDefaultRegistry())  getJobNames(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/JobNames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set and Retrieve Job Names — JobNames","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. names [character] Character vector length provided ids. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobNames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set and Retrieve Job Names — JobNames","text":"setJobNames returns NULL invisibly, getJobTable  returns data.table columns job.id job.name.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JobNames.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set and Retrieve Job Names — JobNames","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' ids = batchMap(identity, 1:10, reg = tmp) #> Adding 10 jobs ... setJobNames(ids, letters[1:nrow(ids)], reg = tmp) getJobNames(reg = tmp) #> Key: <job.id> #>     job.id job.name #>      <int>   <char> #>  1:      1        a #>  2:      2        b #>  3:      3        c #>  4:      4        d #>  5:      5        e #>  6:      6        f #>  7:      7        g #>  8:      8        h #>  9:      9        i #> 10:     10        j"},{"path":"https://batchtools.mlr-org.com/dev/reference/JoinTables.html","id":null,"dir":"Reference","previous_headings":"","what":"Inner, Left, Right, Outer, Semi and Anti Join for Data Tables — JoinTables","title":"Inner, Left, Right, Outer, Semi and Anti Join for Data Tables — JoinTables","text":"helper functions perform join operations data tables. basically one-liners. See https://rpubs.com/ronasta/join_data_tables overview join operations data table alternatively dplyr's vignette two table verbs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JoinTables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inner, Left, Right, Outer, Semi and Anti Join for Data Tables — JoinTables","text":"","code":"ijoin(x, y, by = NULL)  ljoin(x, y, by = NULL)  rjoin(x, y, by = NULL)  ojoin(x, y, by = NULL)  sjoin(x, y, by = NULL)  ajoin(x, y, by = NULL)  ujoin(x, y, all.y = FALSE, by = NULL)"},{"path":"https://batchtools.mlr-org.com/dev/reference/JoinTables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inner, Left, Right, Outer, Semi and Anti Join for Data Tables — JoinTables","text":"x [data.frame] First data.frame join. y [data.frame] Second data.frame join. [character] Column name(s) variables used match rows x y. provided, heuristic similar one described dplyr vignette used: x keyed, existing key used y column(s). x keyed, intersect common columns names used empty. Raise exception. may pass named character vector merge columns different names x y: = c(\"x.id\" = \"y.id\") match x's “x.id” column y\\'s “y.id” column. .y [logical(1)] Keep columns y x?","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JoinTables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inner, Left, Right, Outer, Semi and Anti Join for Data Tables — JoinTables","text":"[data.table] key identical .","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/JoinTables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inner, Left, Right, Outer, Semi and Anti Join for Data Tables — JoinTables","text":"","code":"# Create two tables for demonstration tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(identity, x = 1:6, reg = tmp) #> Adding 6 jobs ... x = getJobPars(reg = tmp) y = findJobs(x >= 2 & x <= 5, reg = tmp) y$extra.col = head(letters, nrow(y))  # Inner join: similar to intersect(): keep all columns of x and y with common matches ijoin(x, y) #> Key: <job.id> #>    job.id  job.pars extra.col #>     <int>    <list>    <char> #> 1:      2 <list[1]>         a #> 2:      3 <list[1]>         b #> 3:      4 <list[1]>         c #> 4:      5 <list[1]>         d  # Left join: use all ids from x, keep all columns of x and y ljoin(x, y) #> Key: <job.id> #>    job.id extra.col  job.pars #>     <int>    <char>    <list> #> 1:      1      <NA> <list[1]> #> 2:      2         a <list[1]> #> 3:      3         b <list[1]> #> 4:      4         c <list[1]> #> 5:      5         d <list[1]> #> 6:      6      <NA> <list[1]>  # Right join: use all ids from y, keep all columns of x and y rjoin(x, y) #> Key: <job.id> #>    job.id  job.pars extra.col #>     <int>    <list>    <char> #> 1:      2 <list[1]>         a #> 2:      3 <list[1]>         b #> 3:      4 <list[1]>         c #> 4:      5 <list[1]>         d  # Outer join: similar to union(): keep all columns of x and y with matches in x or y ojoin(x, y) #> Key: <job.id> #>    job.id  job.pars extra.col #>     <int>    <list>    <char> #> 1:      1 <list[1]>      <NA> #> 2:      2 <list[1]>         a #> 3:      3 <list[1]>         b #> 4:      4 <list[1]>         c #> 5:      5 <list[1]>         d #> 6:      6 <list[1]>      <NA>  # Semi join: filter x with matches in y sjoin(x, y) #> Key: <job.id> #>    job.id  job.pars #>     <int>    <list> #> 1:      2 <list[1]> #> 2:      3 <list[1]> #> 3:      4 <list[1]> #> 4:      5 <list[1]>  # Anti join: filter x with matches not in y ajoin(x, y) #> Key: <job.id> #>    job.id  job.pars #>     <int>    <list> #> 1:      1 <list[1]> #> 2:      6 <list[1]>  # Updating join: Replace values in x with values in y ujoin(x, y) #> Key: <job.id> #>    job.id  job.pars #>     <int>    <list> #> 1:      1 <list[1]> #> 2:      2 <list[1]> #> 3:      3 <list[1]> #> 4:      4 <list[1]> #> 5:      5 <list[1]> #> 6:      6 <list[1]>"},{"path":"https://batchtools.mlr-org.com/dev/reference/Tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Add or Remove Job Tags — Tags","title":"Add or Remove Job Tags — Tags","text":"Add remove arbitrary tags jobs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add or Remove Job Tags — Tags","text":"","code":"addJobTags(ids = NULL, tags, reg = getDefaultRegistry())  removeJobTags(ids = NULL, tags, reg = getDefaultRegistry())  getUsedJobTags(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/Tags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add or Remove Job Tags — Tags","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. tags [character] Tags add remove strings. tag may consist letters, numbers, underscore dots (pattern “^[[:alnum:]_.]+”). reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Tags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add or Remove Job Tags — Tags","text":"[data.table] job ids affected (invisible).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Tags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add or Remove Job Tags — Tags","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' ids = batchMap(sqrt, x = -3:3, reg = tmp) #> Adding 7 jobs ...  # Add new tag to all ids addJobTags(ids, \"needs.computation\", reg = tmp) getJobTags(reg = tmp) #> Key: <job.id> #>    job.id              tags #>     <int>            <char> #> 1:      1 needs.computation #> 2:      2 needs.computation #> 3:      3 needs.computation #> 4:      4 needs.computation #> 5:      5 needs.computation #> 6:      6 needs.computation #> 7:      7 needs.computation  # Add more tags addJobTags(findJobs(x < 0, reg = tmp), \"x.neg\", reg = tmp) addJobTags(findJobs(x > 0, reg = tmp), \"x.pos\", reg = tmp) getJobTags(reg = tmp) #> Key: <job.id> #>    job.id                    tags #>     <int>                  <char> #> 1:      1 needs.computation,x.neg #> 2:      2 needs.computation,x.neg #> 3:      3 needs.computation,x.neg #> 4:      4       needs.computation #> 5:      5 needs.computation,x.pos #> 6:      6 needs.computation,x.pos #> 7:      7 needs.computation,x.pos  # Submit first 5 jobs and remove tag if successful ids = submitJobs(1:5, reg = tmp) #> Submitting 5 jobs in 5 chunks using cluster functions 'Interactive' ... #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced if (waitForJobs(reg = tmp))   removeJobTags(ids, \"needs.computation\", reg = tmp) getJobTags(reg = tmp) #> Key: <job.id> #>    job.id                    tags #>     <int>                  <char> #> 1:      1                   x.neg #> 2:      2                   x.neg #> 3:      3                   x.neg #> 4:      4                    <NA> #> 5:      5                   x.pos #> 6:      6 needs.computation,x.pos #> 7:      7 needs.computation,x.pos  # Grep for warning message and add a tag addJobTags(grepLogs(pattern = \"NaNs produced\", reg = tmp), \"div.zero\", reg = tmp) getJobTags(reg = tmp) #> Key: <job.id> #>    job.id                    tags #>     <int>                  <char> #> 1:      1                   x.neg #> 2:      2                   x.neg #> 3:      3                   x.neg #> 4:      4                    <NA> #> 5:      5                   x.pos #> 6:      6 needs.computation,x.pos #> 7:      7 needs.computation,x.pos  # All tags where tag x.neg is set: ids = findTagged(\"x.neg\", reg = tmp) getUsedJobTags(ids, reg = tmp) #> [1] \"x.neg\""},{"path":"https://batchtools.mlr-org.com/dev/reference/Worker.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Linux-Worker — Worker","title":"Create a Linux-Worker — Worker","text":"R6Class create local remote linux workers.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Worker.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Create a Linux-Worker — Worker","text":"R6Class generator object","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Worker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Linux-Worker — Worker","text":"[Worker].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Worker.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"Create a Linux-Worker — Worker","text":"nodename Host name. Set via constructor. ncpus Number CPUs. Set via constructor defaults heuristic tries detect number CPUs machine. max.load Maximum load average (last 5 min). Set via constructor defaults number CPUs machine. status Status worker; one “unknown”, “available”, “max.cpus” “max.load”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Worker.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Create a Linux-Worker — Worker","text":"new(nodename, ncpus, max.load) Constructor. update(reg) Update worker status. list(reg) List running jobs. start(reg, fn, outfile) Start job collection file “fn” output “outfile”. kill(reg, batch.id) Kill job matching “batch.id”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/Worker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Linux-Worker — Worker","text":"","code":"if (FALSE) { # \\dontrun{ # create a worker for the local machine and use 4 CPUs. Worker$new(\"localhost\", ncpus = 4) } # }"},{"path":"https://batchtools.mlr-org.com/dev/reference/addAlgorithm.html","id":null,"dir":"Reference","previous_headings":"","what":"Define Algorithms for Experiments — addAlgorithm","title":"Define Algorithms for Experiments — addAlgorithm","text":"Algorithms functions get data part well problem instance (return value function defined Problem) return arbitrary R object. function serializes components file system registers algorithm ExperimentRegistry. removeAlgorithm removes jobs registry depend specific algorithm. reg$algorithms holds IDs already defined algorithms.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addAlgorithm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define Algorithms for Experiments — addAlgorithm","text":"","code":"addAlgorithm(name, fun = NULL, reg = getDefaultRegistry())  removeAlgorithms(name, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/addAlgorithm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define Algorithms for Experiments — addAlgorithm","text":"name [character(1)] Unique identifier algorithm. fun [function]   algorithm function. static problem part passed “data”, generated   problem instance passed “instance” Job/Experiment “job”.   Therefore, function must formal arguments “job”, “data” “instance” (dots ...). provide function, defaults function just returns instance. reg [ExperimentRegistry] Registry. explicitly passed, uses last created registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addAlgorithm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define Algorithms for Experiments — addAlgorithm","text":"[Algorithm]. Object class “Algorithm”.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/addExperiments.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Experiments to the Registry — addExperiments","title":"Add Experiments to the Registry — addExperiments","text":"Adds experiments (parametrized combinations problems algorithms) registry thereby defines batch jobs. multiple problem designs algorithm designs provided, combined via Cartesian product. E.g., two problems p1 p2 three algorithms a1, a2 a3, addExperiments creates experiments parameters combinations (p1, a1), (p1, a2), (p1, a3), (p2, a1), (p2, a2) (p2, a3).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addExperiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Experiments to the Registry — addExperiments","text":"","code":"addExperiments(   prob.designs = NULL,   algo.designs = NULL,   repls = 1L,   combine = \"crossprod\",   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/addExperiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Experiments to the Registry — addExperiments","text":"prob.designs [named list data.frame] Named list data frames (data.table). name must match problem name column names correspond parameters problem. NULL, experiments defined problems without parameters added. algo.designs [named list data.table data.frame] Named list data frames (data.table). name must match algorithm name column names correspond parameters algorithm. NULL, experiments defined algorithms without parameters added. repls [integer()] Number replications problem design `prob.designs` (automatically replicated correct length). combine [character(1)] combine rows single problem design rows single algorithm design? Default “crossprod” combines row problem design row algorithm design cross-product fashion. Set “bind” just cbind tables problem algorithm designs shorter table repeated necessary. reg [ExperimentRegistry] Registry. explicitly passed, uses last created registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addExperiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Experiments to the Registry — addExperiments","text":"[data.table] ids added jobs stored column “job.id”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addExperiments.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Add Experiments to the Registry — addExperiments","text":"R's data.frame converts character vectors factors default R versions prior 4.0.0 frequently resulted problems using addExperiments. Therefore, function warn factor variables following conditions hold: R version < 4.0.0 design passed data.frame, data.table tibble. option “stringsAsFactors” set set TRUE.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/addExperiments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Experiments to the Registry — addExperiments","text":"","code":"tmp = makeExperimentRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive'  # add first problem fun = function(job, data, n, mean, sd, ...) rnorm(n, mean = mean, sd = sd) addProblem(\"rnorm\", fun = fun, reg = tmp) #> Adding problem 'rnorm'  # add second problem fun = function(job, data, n, lambda, ...) rexp(n, rate = lambda) addProblem(\"rexp\", fun = fun, reg = tmp) #> Adding problem 'rexp'  # add first algorithm fun = function(instance, method, ...) if (method == \"mean\") mean(instance) else median(instance) addAlgorithm(\"average\", fun = fun, reg = tmp) #> Adding algorithm 'average'  # add second algorithm fun = function(instance, ...) sd(instance) addAlgorithm(\"deviation\", fun = fun, reg = tmp) #> Adding algorithm 'deviation'  # define problem and algorithm designs library(data.table) prob.designs = algo.designs = list() prob.designs$rnorm = CJ(n = 100, mean = -1:1, sd = 1:5) prob.designs$rexp = data.table(n = 100, lambda = 1:5) algo.designs$average = data.table(method = c(\"mean\", \"median\")) algo.designs$deviation = data.table()  # add experiments and submit addExperiments(prob.designs, algo.designs, reg = tmp) #> Adding 30 experiments ('rnorm'[15] x 'average'[2] x repls[1]) ... #> Adding 15 experiments ('rnorm'[15] x 'deviation'[1] x repls[1]) ... #> Adding 10 experiments ('rexp'[5] x 'average'[2] x repls[1]) ... #> Adding 5 experiments ('rexp'[5] x 'deviation'[1] x repls[1]) ...  # check what has been created summarizeExperiments(reg = tmp) #>    problem algorithm .count #>     <char>    <char>  <int> #> 1:   rnorm   average     30 #> 2:   rnorm deviation     15 #> 3:    rexp   average     10 #> 4:    rexp deviation      5 unwrap(getJobPars(reg = tmp)) #> Key: <job.id> #>     job.id problem algorithm     n  mean    sd lambda method #>      <int>  <char>    <char> <num> <int> <int>  <int> <char> #>  1:      1   rnorm   average   100    -1     1     NA   mean #>  2:      2   rnorm   average   100    -1     1     NA median #>  3:      3   rnorm   average   100    -1     2     NA   mean #>  4:      4   rnorm   average   100    -1     2     NA median #>  5:      5   rnorm   average   100    -1     3     NA   mean #>  6:      6   rnorm   average   100    -1     3     NA median #>  7:      7   rnorm   average   100    -1     4     NA   mean #>  8:      8   rnorm   average   100    -1     4     NA median #>  9:      9   rnorm   average   100    -1     5     NA   mean #> 10:     10   rnorm   average   100    -1     5     NA median #> 11:     11   rnorm   average   100     0     1     NA   mean #> 12:     12   rnorm   average   100     0     1     NA median #> 13:     13   rnorm   average   100     0     2     NA   mean #> 14:     14   rnorm   average   100     0     2     NA median #> 15:     15   rnorm   average   100     0     3     NA   mean #> 16:     16   rnorm   average   100     0     3     NA median #> 17:     17   rnorm   average   100     0     4     NA   mean #> 18:     18   rnorm   average   100     0     4     NA median #> 19:     19   rnorm   average   100     0     5     NA   mean #> 20:     20   rnorm   average   100     0     5     NA median #> 21:     21   rnorm   average   100     1     1     NA   mean #> 22:     22   rnorm   average   100     1     1     NA median #> 23:     23   rnorm   average   100     1     2     NA   mean #> 24:     24   rnorm   average   100     1     2     NA median #> 25:     25   rnorm   average   100     1     3     NA   mean #> 26:     26   rnorm   average   100     1     3     NA median #> 27:     27   rnorm   average   100     1     4     NA   mean #> 28:     28   rnorm   average   100     1     4     NA median #> 29:     29   rnorm   average   100     1     5     NA   mean #> 30:     30   rnorm   average   100     1     5     NA median #> 31:     31   rnorm deviation   100    -1     1     NA   <NA> #> 32:     32   rnorm deviation   100    -1     2     NA   <NA> #> 33:     33   rnorm deviation   100    -1     3     NA   <NA> #> 34:     34   rnorm deviation   100    -1     4     NA   <NA> #> 35:     35   rnorm deviation   100    -1     5     NA   <NA> #> 36:     36   rnorm deviation   100     0     1     NA   <NA> #> 37:     37   rnorm deviation   100     0     2     NA   <NA> #> 38:     38   rnorm deviation   100     0     3     NA   <NA> #> 39:     39   rnorm deviation   100     0     4     NA   <NA> #> 40:     40   rnorm deviation   100     0     5     NA   <NA> #> 41:     41   rnorm deviation   100     1     1     NA   <NA> #> 42:     42   rnorm deviation   100     1     2     NA   <NA> #> 43:     43   rnorm deviation   100     1     3     NA   <NA> #> 44:     44   rnorm deviation   100     1     4     NA   <NA> #> 45:     45   rnorm deviation   100     1     5     NA   <NA> #> 46:     46    rexp   average   100    NA    NA      1   mean #> 47:     47    rexp   average   100    NA    NA      1 median #> 48:     48    rexp   average   100    NA    NA      2   mean #> 49:     49    rexp   average   100    NA    NA      2 median #> 50:     50    rexp   average   100    NA    NA      3   mean #> 51:     51    rexp   average   100    NA    NA      3 median #> 52:     52    rexp   average   100    NA    NA      4   mean #> 53:     53    rexp   average   100    NA    NA      4 median #> 54:     54    rexp   average   100    NA    NA      5   mean #> 55:     55    rexp   average   100    NA    NA      5 median #> 56:     56    rexp deviation   100    NA    NA      1   <NA> #> 57:     57    rexp deviation   100    NA    NA      2   <NA> #> 58:     58    rexp deviation   100    NA    NA      3   <NA> #> 59:     59    rexp deviation   100    NA    NA      4   <NA> #> 60:     60    rexp deviation   100    NA    NA      5   <NA> #>     job.id problem algorithm     n  mean    sd lambda method"},{"path":"https://batchtools.mlr-org.com/dev/reference/addProblem.html","id":null,"dir":"Reference","previous_headings":"","what":"Define Problems for Experiments — addProblem","title":"Define Problems for Experiments — addProblem","text":"Problems may consist two parts: static, immutable part (data addProblem) dynamic, stochastic part (fun addProblem). example, statistical learning problems data frame static problem part resampling function stochastic part creates problem instance. instance typically passed learning algorithm like wrapper around statistical model (fun addAlgorithm). function serialize components file system registers problem ExperimentRegistry. removeProblem removes jobs registry depend specific problem. reg$problems holds IDs already defined problems.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addProblem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define Problems for Experiments — addProblem","text":"","code":"addProblem(   name,   data = NULL,   fun = NULL,   seed = NULL,   cache = FALSE,   reg = getDefaultRegistry() )  removeProblems(name, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/addProblem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define Problems for Experiments — addProblem","text":"name [character(1)] Unique identifier problem. data [] Static problem part. Default NULL. fun [function] function defining stochastic problem part. static part passed function name “data” Job/Experiment passed “job”. Therefore, function must formal arguments “job” “data” (dots ...). provide function, defaults function just returns data part. seed [integer(1)] Start seed problem. allows “synchronization” stochastic problem across algorithms, different algorithms evaluated stochastic instance. problem seed defined, seeding mechanism works follows: (1) dynamic part problem instantiated, seed problem + [replication number] - 1 set, .e. first replication uses problem seed. (2) stochastic part problem instantiated. (3) now usual experiment seed registry used, see ExperimentRegistry. seed set NULL (default), job seed used instantiate problem different algorithms see different stochastic instances problem. cache [logical(1)] TRUE seed set, problem instances cached file system. assumes problem instance deterministic combination hyperparameter setting replication number. feature experimental. reg [ExperimentRegistry] Registry. explicitly passed, uses last created registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/addProblem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define Problems for Experiments — addProblem","text":"[Problem]. Object class “Problem” (invisibly).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/addProblem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define Problems for Experiments — addProblem","text":"","code":"tmp = makeExperimentRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' addProblem(\"p1\", fun = function(job, data) data, reg = tmp) #> Adding problem 'p1' addProblem(\"p2\", fun = function(job, data) job, reg = tmp) #> Adding problem 'p2' addAlgorithm(\"a1\", fun = function(job, data, instance) instance, reg = tmp) #> Adding algorithm 'a1' addExperiments(repls = 2, reg = tmp) #> Adding 2 experiments ('p1'[1] x 'a1'[1] x repls[2]) ... #> Adding 2 experiments ('p2'[1] x 'a1'[1] x repls[2]) ...  # List problems, algorithms and job parameters: tmp$problems #> [1] \"p1\" \"p2\" tmp$algorithms #> [1] \"a1\" getJobPars(reg = tmp) #> Key: <job.id> #>    job.id problem prob.pars algorithm algo.pars #>     <int>  <char>    <list>    <char>    <list> #> 1:      1      p1 <list[0]>        a1 <list[0]> #> 2:      2      p1 <list[0]>        a1 <list[0]> #> 3:      3      p2 <list[0]>        a1 <list[0]> #> 4:      4      p2 <list[0]>        a1 <list[0]>  # Remove one problem removeProblems(\"p1\", reg = tmp) #> Removing Problem 'p1' and 2 corresponding jobs ...  # List problems and algorithms: tmp$problems #> [1] \"p2\" tmp$algorithms #> [1] \"a1\" getJobPars(reg = tmp) #> Key: <job.id> #>    job.id problem prob.pars algorithm algo.pars #>     <int>  <char>    <list>    <char>    <list> #> 1:      3      p2 <list[0]>        a1 <list[0]> #> 2:      4      p2 <list[0]>        a1 <list[0]>"},{"path":"https://batchtools.mlr-org.com/dev/reference/assertRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"assertRegistry — assertRegistry","title":"assertRegistry — assertRegistry","text":"Assert given object batchtools registry. Additionally can sync registry, check writeable, check jobs running. check fails, throws error indicting reason failure.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/assertRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"assertRegistry — assertRegistry","text":"","code":"assertRegistry(   reg,   class = NULL,   writeable = FALSE,   sync = FALSE,   running.ok = TRUE )"},{"path":"https://batchtools.mlr-org.com/dev/reference/assertRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"assertRegistry — assertRegistry","text":"reg [Registry] object asserted Registry. class [character(1)] NULL (default), reg must inherit class “Registry”. Otherwise check reg class class. E.g., set “Registry”, ExperimentRegistry pass. writeable [logical(1)] Check registry writeable. sync [logical(1)] Try synchronize registry including pending results file system. See syncRegistry. running.ok [logical(1)] FALSE throw error jobs associated registry currently running.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/assertRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"assertRegistry — assertRegistry","text":"TRUE invisibly.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchExport.html","id":null,"dir":"Reference","previous_headings":"","what":"Export Objects to the Slaves — batchExport","title":"Export Objects to the Slaves — batchExport","text":"Objects saved subdirectory “exports” “file.dir” reg. automatically loaded placed global environment time registry loaded job collection executed.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchExport.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export Objects to the Slaves — batchExport","text":"","code":"batchExport(   export = list(),   unexport = character(0L),   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchExport.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export Objects to the Slaves — batchExport","text":"export [list] Named list objects export. unexport [character] Vector object names unexport. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchExport.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export Objects to the Slaves — batchExport","text":"[data.table] name uri exported objects.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchExport.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export Objects to the Slaves — batchExport","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive'  # list exports exports = batchExport(reg = tmp) print(exports) #> Empty data.table (0 rows and 2 cols): name,uri  # add a job and required exports batchMap(function(x) x^2 + y + z, x = 1:3, reg = tmp) #> Adding 3 jobs ... exports = batchExport(export = list(y = 99, z = 1), reg = tmp) #> Exporting new objects: 'y','z' ... print(exports) #>      name                                        uri #>    <char>                                  <fs_path> #> 1:      y /tmp/batchtools-example/reg/exports/PE.rds #> 2:      z /tmp/batchtools-example/reg/exports/PI.rds  submitJobs(reg = tmp) #> Submitting 3 jobs in 3 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE stopifnot(loadResult(1, reg = tmp) == 101)  # Un-export z exports = batchExport(unexport = \"z\", reg = tmp) #> Un-exporting exported objects: 'z' ... print(exports) #>      name                                        uri #>    <char>                                  <fs_path> #> 1:      y /tmp/batchtools-example/reg/exports/PE.rds"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMap.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Operation for Batch Systems — batchMap","title":"Map Operation for Batch Systems — batchMap","text":"parallel asynchronous Map/mapply batch systems. Note function defines computational jobs. actual computation started submitJobs. Results partial results can collected reduceResultsList, reduceResults loadResult. synchronous Map-like execution, see btmapply.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Operation for Batch Systems — batchMap","text":"","code":"batchMap(   fun,   ...,   args = list(),   more.args = list(),   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Operation for Batch Systems — batchMap","text":"fun [function] Function map arguments provided via .... Parameters given via args ... passed -, respective order possibly named. function named formal argument “.job”, Job passed function slave. ... [] Arguments vectorize (list vector). Shorter vectors recycled (possibly warning length multiple longest length). Mutually exclusive args. Note although possible iterate large objects (e.g., lists data frames matrices), usually hurts overall performance thus discouraged. args [list | data.frame] Arguments vectorize (named) list data frame. Shorter vectors recycled (possibly warning length multiple longest length). Mutually exclusive .... .args [list] list arguments passed fun. Default empty list. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Operation for Batch Systems — batchMap","text":"[data.table] ids added jobs stored column “job.id”.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map Operation for Batch Systems — batchMap","text":"","code":"# example using \"...\" and more.args tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg1' using cluster functions 'Interactive' f = function(x, y) x^2 + y ids = batchMap(f, x = 1:10, more.args = list(y = 100), reg = tmp) #> Adding 10 jobs ... getJobPars(reg = tmp) #> Key: <job.id> #>     job.id  job.pars #>      <int>    <list> #>  1:      1 <list[1]> #>  2:      2 <list[1]> #>  3:      3 <list[1]> #>  4:      4 <list[1]> #>  5:      5 <list[1]> #>  6:      6 <list[1]> #>  7:      7 <list[1]> #>  8:      8 <list[1]> #>  9:      9 <list[1]> #> 10:     10 <list[1]> testJob(6, reg = tmp) # 100 + 6^2 = 136 #> ### [bt]: Setting seed to 12787 ... #> [1] 136  # vector recycling tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg2' using cluster functions 'Interactive' f = function(...) list(...) ids = batchMap(f, x = 1:3, y = 1:6, reg = tmp) #> Adding 6 jobs ... getJobPars(reg = tmp) #> Key: <job.id> #>    job.id  job.pars #>     <int>    <list> #> 1:      1 <list[2]> #> 2:      2 <list[2]> #> 3:      3 <list[2]> #> 4:      4 <list[2]> #> 5:      5 <list[2]> #> 6:      6 <list[2]>  # example for an expand.grid()-like operation on parameters tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg3' using cluster functions 'Interactive' ids = batchMap(paste, args = data.table::CJ(x = letters[1:3], y = 1:3), reg = tmp) #> Adding 9 jobs ... getJobPars(reg = tmp) #> Key: <job.id> #>    job.id  job.pars #>     <int>    <list> #> 1:      1 <list[2]> #> 2:      2 <list[2]> #> 3:      3 <list[2]> #> 4:      4 <list[2]> #> 5:      5 <list[2]> #> 6:      6 <list[2]> #> 7:      7 <list[2]> #> 8:      8 <list[2]> #> 9:      9 <list[2]> testJob(6, reg = tmp) #> ### [bt]: Setting seed to 8571 ... #> [1] \"b 3\""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMapResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Over Results to Create New Jobs — batchMapResults","title":"Map Over Results to Create New Jobs — batchMapResults","text":"function allows create new computational jobs (just like batchMap based results Registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMapResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Over Results to Create New Jobs — batchMapResults","text":"","code":"batchMapResults(   fun,   ids = NULL,   ...,   more.args = list(),   target,   source = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMapResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Over Results to Create New Jobs — batchMapResults","text":"fun [function] Function takes result first (unnamed) argument. ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findDone. Invalid ids ignored. ... [] Arguments vectorize (list vector). Passed batchMap. .args [list] list arguments passed fun. Default empty list. target [Registry] Empty Registry new jobs created . source [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMapResults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Over Results to Create New Jobs — batchMapResults","text":"[data.table] ids jobs added target.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMapResults.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Map Over Results to Create New Jobs — batchMapResults","text":"URI result files registry source hard coded parameter target registry. means target currently portable systems computation.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/batchMapResults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map Over Results to Create New Jobs — batchMapResults","text":"","code":"# Source registry: calculate square of some numbers tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg1' using cluster functions 'Interactive' batchMap(function(x) list(square = x^2), x = 1:10, reg = tmp) #> Adding 10 jobs ... submitJobs(reg = tmp) #> Submitting 10 jobs in 10 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE  # Target registry: calculate the square root on results of first registry target = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg2' using cluster functions 'Interactive' batchMapResults(fun = function(x, y) list(sqrt = sqrt(x$square)), ids = 4:8,   target = target, source = tmp) #> Adding 5 jobs ... submitJobs(reg = target) #> Submitting 5 jobs in 5 chunks using cluster functions 'Interactive' ... waitForJobs(reg = target) #> [1] TRUE  # Map old to new ids. First, get a table with results and parameters results = unwrap(rjoin(getJobPars(reg = target), reduceResultsDataTable(reg = target))) print(results) #> Key: <job.id> #>    job.id   .id  sqrt #>     <int> <int> <num> #> 1:      1     4     4 #> 2:      2     5     5 #> 3:      3     6     6 #> 4:      4     7     7 #> 5:      5     8     8  # Parameter '.id' points to job.id in 'source'. Use a inner join to combine: ijoin(results, unwrap(reduceResultsDataTable(reg = tmp)), by = c(\".id\" = \"job.id\")) #> Key: <.id> #>    job.id   .id  sqrt square #>     <int> <int> <num>  <num> #> 1:      1     4     4     16 #> 2:      2     5     5     25 #> 3:      3     6     6     36 #> 4:      4     7     7     49 #> 5:      5     8     8     64"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchReduce.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce Operation for Batch Systems — batchReduce","title":"Reduce Operation for Batch Systems — batchReduce","text":"parallel asynchronous Reduce batch systems. Note function defines computational jobs. job reduces certain number elements one slave. actual computation started submitJobs. Results partial results can collected reduceResultsList, reduceResults loadResult.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchReduce.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce Operation for Batch Systems — batchReduce","text":"","code":"batchReduce(   fun,   xs,   init = NULL,   chunks = seq_along(xs),   more.args = list(),   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchReduce.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce Operation for Batch Systems — batchReduce","text":"fun [function(aggr, x, ...)] Function reduce xs . xs [vector] Vector reduce. init [] Initial object reducing. See Reduce. chunks [integer(length(xs))] Group element xs. Can generated chunk. .args [list] list additional arguments passed fun. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchReduce.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce Operation for Batch Systems — batchReduce","text":"[data.table] ids added jobs stored column “job.id”.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/batchReduce.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce Operation for Batch Systems — batchReduce","text":"","code":"# define function to reduce on slave, we want to sum a vector tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' xs = 1:100 f = function(aggr, x) aggr + x  # sum 20 numbers on each slave process, i.e. 5 jobs chunks = chunk(xs, chunk.size = 5) batchReduce(fun = f, 1:100, init = 0, chunks = chunks, reg = tmp) #> Adding 20 jobs ... submitJobs(reg = tmp) #> Submitting 20 jobs in 20 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE  # now reduce one final time on master reduceResults(fun = function(aggr, job, res) f(aggr, res), reg = tmp) #> [1] 5050"},{"path":"https://batchtools.mlr-org.com/dev/reference/batchtools-package.html","id":null,"dir":"Reference","previous_headings":"","what":"batchtools: Tools for Computation on Batch Systems — batchtools-package","title":"batchtools: Tools for Computation on Batch Systems — batchtools-package","text":"bug reports feature requests please use tracker: https://github.com/mllg/batchtools.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/batchtools-package.html","id":"package-options","dir":"Reference","previous_headings":"","what":"Package options","title":"batchtools: Tools for Computation on Batch Systems — batchtools-package","text":"batchtools.verbose Verbosity. Set FALSE suppress info messages progress bars. batchtools.progress Progress bars. Set FALSE disable . batchtools.timestamps Add time stamps log output. Set FALSE disable . Furthermore, may enable debug mode using debugme package setting environment variable “DEBUGME” “batchtools” loading batchtools.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/batchtools-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"batchtools: Tools for Computation on Batch Systems — batchtools-package","text":"Maintainer: Michel Lang michellang@gmail.com (ORCID) Authors: Bernd Bischl bernd_bischl@gmx.net contributors: Dirk Surmann surmann@statistik.tu-dortmund.de (ORCID) [contributor]","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/btlapply.html","id":null,"dir":"Reference","previous_headings":"","what":"Synchronous Apply Functions — btlapply","title":"Synchronous Apply Functions — btlapply","text":"set functions acting counterparts sequential popular apply functions base R: btlapply lapply btmapply mapply. Internally, jobs created using batchMap provided registry. registry provided, temporary registry (see argument file.dir makeRegistry) batchMap used. jobs terminated (see waitForJobs), results collected returned list. Note functions suitable short fail-safe operations batch system. jobs fail, retrieve partial results registry directory .","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/btlapply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synchronous Apply Functions — btlapply","text":"","code":"btlapply(   X,   fun,   ...,   resources = list(),   n.chunks = NULL,   chunk.size = NULL,   reg = makeRegistry(file.dir = NA) )  btmapply(   fun,   ...,   more.args = list(),   simplify = FALSE,   use.names = TRUE,   resources = list(),   n.chunks = NULL,   chunk.size = NULL,   reg = makeRegistry(file.dir = NA) )"},{"path":"https://batchtools.mlr-org.com/dev/reference/btlapply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synchronous Apply Functions — btlapply","text":"X [vector] Vector apply . fun [function] Function apply. ... [] Additional arguments passed fun (btlapply) vectors map (btmapply). resources [named list] Computational  resources jobs submit. actual elements list (e.g. something like “walltime” “nodes”) depend template file, exceptions outlined section 'Resources'. Default settings system can set configuration file defining named list default.resources. Note settings merged name, e.g. merging list(walltime = 300) list(walltime = 400, memory = 512) result list(walltime = 300, memory = 512). holds individual job resources passed additional column ids (c.f. section 'Resources'). n.chunks [integer(1)] Passed chunk submitJobs. chunk.size [integer(1)] Passed chunk submitJobs. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry). .args [list] Additional arguments passed fun. simplify [logical(1)] Simplify results using simplify2array? use.names [logical(1)] Use names input name output?","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/btlapply.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synchronous Apply Functions — btlapply","text":"[list] List results function call.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/btlapply.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synchronous Apply Functions — btlapply","text":"","code":"btlapply(1:3, function(x) x^2) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' #> Adding 3 jobs ... #> Submitting 3 jobs in 3 chunks using cluster functions 'Interactive' ... #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 4 #>  #> [[3]] #> [1] 9 #>  btmapply(function(x, y, z) x + y + z, x = 1:3, y = 1:3, more.args = list(z = 1), simplify = TRUE) #> No readable configuration file found #> Created registry in '/tmp/RtmpdLswKT/registry218e737f1043' using cluster functions 'Interactive' #> Adding 3 jobs ... #> Submitting 3 jobs in 3 chunks using cluster functions 'Interactive' ... #> [1] 3 5 7"},{"path":"https://batchtools.mlr-org.com/dev/reference/cfBrewTemplate.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster Functions Helper to Write Job Description Files — cfBrewTemplate","title":"Cluster Functions Helper to Write Job Description Files — cfBrewTemplate","text":"function intended use cluster functions implementation. Calls brew silently template, error lead exception. file stored place corresponding job file “jobs”-subdir files directory.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfBrewTemplate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster Functions Helper to Write Job Description Files — cfBrewTemplate","text":"","code":"cfBrewTemplate(reg, text, jc)"},{"path":"https://batchtools.mlr-org.com/dev/reference/cfBrewTemplate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster Functions Helper to Write Job Description Files — cfBrewTemplate","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry). text [character(1)] String ready brewed. See cfReadBrewTemplate read template file system. jc [JobCollection)] used environment brew template file . See JobCollection list available variables.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfBrewTemplate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster Functions Helper to Write Job Description Files — cfBrewTemplate","text":"[character(1)]. File path brewed template file.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/cfHandleUnknownSubmitError.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster Functions Helper to Handle Unknown Errors — cfHandleUnknownSubmitError","title":"Cluster Functions Helper to Handle Unknown Errors — cfHandleUnknownSubmitError","text":"function intended use cluster functions implementation. Simply constructs SubmitJobResult object status code 101, NA batch id informative error message containing output OS command output.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfHandleUnknownSubmitError.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster Functions Helper to Handle Unknown Errors — cfHandleUnknownSubmitError","text":"","code":"cfHandleUnknownSubmitError(cmd, exit.code, output)"},{"path":"https://batchtools.mlr-org.com/dev/reference/cfHandleUnknownSubmitError.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster Functions Helper to Handle Unknown Errors — cfHandleUnknownSubmitError","text":"cmd [character(1)] OS command used submit job, e.g. qsub. exit.code [integer(1)] Exit code OS command, 0. output [character] Output OS command, hopefully informative error message. multiple lines vector, automatically joined.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfHandleUnknownSubmitError.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster Functions Helper to Handle Unknown Errors — cfHandleUnknownSubmitError","text":"[SubmitJobResult].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/cfKillJob.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster Functions Helper to Kill Batch Jobs — cfKillJob","title":"Cluster Functions Helper to Kill Batch Jobs — cfKillJob","text":"function intended use cluster functions implementation. Calls OS command kill job via system like : “cmd batch.job.id”. command returns exit code > 0, command repeated 1 second sleep max.tries-1 times. command failed tries, error generated.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfKillJob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster Functions Helper to Kill Batch Jobs — cfKillJob","text":"","code":"cfKillJob(   reg,   cmd,   args = character(0L),   max.tries = 3L,   nodename = \"localhost\" )"},{"path":"https://batchtools.mlr-org.com/dev/reference/cfKillJob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster Functions Helper to Kill Batch Jobs — cfKillJob","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry). cmd [character(1)] OS command, e.g. “qdel”. args [character] Arguments cmd, including batch id. max.tries [integer(1)] Number total times try execute OS command cases failures. Default 3. nodename [character(1)] Name SSH node run command . set “localhost” (default), command piped SSH.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfKillJob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster Functions Helper to Kill Batch Jobs — cfKillJob","text":"TRUE success. exception raised otherwise.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/cfReadBrewTemplate.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster Functions Helper to Parse a Brew Template — cfReadBrewTemplate","title":"Cluster Functions Helper to Parse a Brew Template — cfReadBrewTemplate","text":"function intended use cluster functions implementation. function intended use cluster functions implementation. Simply reads template file returns character vector.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfReadBrewTemplate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster Functions Helper to Parse a Brew Template — cfReadBrewTemplate","text":"","code":"cfReadBrewTemplate(template, comment.string = NA_character_)"},{"path":"https://batchtools.mlr-org.com/dev/reference/cfReadBrewTemplate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster Functions Helper to Parse a Brew Template — cfReadBrewTemplate","text":"template [character(1)] Path template file passed brew. comment.string [character(1)] Ignore lines starting string.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/cfReadBrewTemplate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster Functions Helper to Parse a Brew Template — cfReadBrewTemplate","text":"[character].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/chunk.html","id":null,"dir":"Reference","previous_headings":"","what":"Chunk Jobs for Sequential Execution — chunk","title":"Chunk Jobs for Sequential Execution — chunk","text":"Jobs can partitioned “chunks” executed sequentially computational nodes. Chunks defined providing data frame columns “job.id” “chunk” (integer) submitJobs. jobs chunk number grouped together one node form single computational job. function chunk simply splits x either fixed number groups, variable number groups fixed number maximum elements. function lpt also groups x fixed number chunks, uses actual values x greedy “Longest Processing Time” algorithm. result, maximum sum elements minimized. binpack splits x variable number groups whose sum elements exceed upper limit provided chunk.size. See examples estimateRuntimes application binpack lpt.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/chunk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chunk Jobs for Sequential Execution — chunk","text":"","code":"chunk(x, n.chunks = NULL, chunk.size = NULL, shuffle = TRUE)  lpt(x, n.chunks = 1L)  binpack(x, chunk.size = max(x))"},{"path":"https://batchtools.mlr-org.com/dev/reference/chunk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chunk Jobs for Sequential Execution — chunk","text":"x [numeric] chunk atomic vector (usually job.id). binpack lpt, weights group. n.chunks [integer(1)] Requested number chunks. function chunk distributes number elements x evenly lpt tries even sum elements chunk. chunks necessary requested, empty chunks ignored. Mutually exclusive chunks.size. chunk.size [integer(1)] Requested chunk size single chunk. chunk number elements x, binpack size determined sum values x. Mutually exclusive n.chunks. shuffle [logical(1)] Shuffles groups. Default TRUE.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/chunk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chunk Jobs for Sequential Execution — chunk","text":"[integer] giving chunk number element x.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/chunk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chunk Jobs for Sequential Execution — chunk","text":"","code":"ch = chunk(1:10, n.chunks = 2) table(ch) #> ch #> 1 2  #> 5 5   ch = chunk(rep(1, 10), chunk.size = 2) table(ch) #> ch #> 1 2 3 4 5  #> 2 2 2 2 2   set.seed(1) x = runif(10) ch = lpt(x, n.chunks = 2) sapply(split(x, ch), sum) #>        1        2  #> 2.808393 2.706746   set.seed(1) x = runif(10) ch = binpack(x, 1) sapply(split(x, ch), sum) #>         1         2         3         4         5         6  #> 0.9446753 0.9699941 0.8983897 0.9263065 0.8307960 0.9449773   # Job chunking tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg1' using cluster functions 'Interactive' ids = batchMap(identity, 1:25, reg = tmp) #> Adding 25 jobs ...  ### Group into chunks with 10 jobs each library(data.table) ids[, chunk := chunk(job.id, chunk.size = 10)] #> Key: <job.id> #>     job.id chunk #>      <int> <int> #>  1:      1     3 #>  2:      2     1 #>  3:      3     1 #>  4:      4     2 #>  5:      5     3 #>  6:      6     1 #>  7:      7     3 #>  8:      8     3 #>  9:      9     2 #> 10:     10     1 #> 11:     11     1 #> 12:     12     2 #> 13:     13     2 #> 14:     14     1 #> 15:     15     2 #> 16:     16     1 #> 17:     17     3 #> 18:     18     1 #> 19:     19     2 #> 20:     20     1 #> 21:     21     2 #> 22:     22     3 #> 23:     23     2 #> 24:     24     3 #> 25:     25     3 #>     job.id chunk print(ids[, .N, by = chunk]) #>    chunk     N #>    <int> <int> #> 1:     3     8 #> 2:     1     9 #> 3:     2     8  ### Group into 4 chunks ids[, chunk := chunk(job.id, n.chunks = 4)] #> Key: <job.id> #>     job.id chunk #>      <int> <int> #>  1:      1     2 #>  2:      2     3 #>  3:      3     4 #>  4:      4     3 #>  5:      5     4 #>  6:      6     1 #>  7:      7     4 #>  8:      8     1 #>  9:      9     2 #> 10:     10     2 #> 11:     11     3 #> 12:     12     3 #> 13:     13     4 #> 14:     14     1 #> 15:     15     3 #> 16:     16     2 #> 17:     17     1 #> 18:     18     2 #> 19:     19     3 #> 20:     20     4 #> 21:     21     1 #> 22:     22     2 #> 23:     23     4 #> 24:     24     1 #> 25:     25     1 #>     job.id chunk print(ids[, .N, by = chunk]) #>    chunk     N #>    <int> <int> #> 1:     2     6 #> 2:     3     6 #> 3:     4     6 #> 4:     1     7  ### Submit to batch system submitJobs(ids = ids, reg = tmp) #> Submitting 25 jobs in 4 chunks using cluster functions 'Interactive' ...  # Grouped chunking tmp = makeExperimentRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg2' using cluster functions 'Interactive' prob = addProblem(reg = tmp, \"prob1\", data = iris, fun = function(job, data) nrow(data)) #> Adding problem 'prob1' prob = addProblem(reg = tmp, \"prob2\", data = Titanic, fun = function(job, data) nrow(data)) #> Adding problem 'prob2' algo = addAlgorithm(reg = tmp, \"algo\", fun = function(job, data, instance, i, ...) problem) #> Adding algorithm 'algo' prob.designs = list(prob1 = data.table(), prob2 = data.table(x = 1:2)) algo.designs = list(algo = data.table(i = 1:3)) addExperiments(prob.designs, algo.designs, repls = 3, reg = tmp) #> Adding 9 experiments ('prob1'[1] x 'algo'[3] x repls[3]) ... #> Adding 18 experiments ('prob2'[2] x 'algo'[3] x repls[3]) ...  ### Group into chunks of 5 jobs, but do not put multiple problems into the same chunk # -> only one problem has to be loaded per chunk, and only once because it is cached ids = getJobTable(reg = tmp)[, .(job.id, problem, algorithm)] ids[, chunk := chunk(job.id, chunk.size = 5), by = \"problem\"] #> Key: <job.id> #>     job.id problem algorithm chunk #>      <int>  <char>    <char> <int> #>  1:      1   prob1      algo     1 #>  2:      2   prob1      algo     1 #>  3:      3   prob1      algo     2 #>  4:      4   prob1      algo     2 #>  5:      5   prob1      algo     1 #>  6:      6   prob1      algo     2 #>  7:      7   prob1      algo     1 #>  8:      8   prob1      algo     1 #>  9:      9   prob1      algo     2 #> 10:     10   prob2      algo     2 #> 11:     11   prob2      algo     1 #> 12:     12   prob2      algo     1 #> 13:     13   prob2      algo     3 #> 14:     14   prob2      algo     3 #> 15:     15   prob2      algo     3 #> 16:     16   prob2      algo     2 #> 17:     17   prob2      algo     2 #> 18:     18   prob2      algo     2 #> 19:     19   prob2      algo     2 #> 20:     20   prob2      algo     4 #> 21:     21   prob2      algo     1 #> 22:     22   prob2      algo     1 #> 23:     23   prob2      algo     3 #> 24:     24   prob2      algo     4 #> 25:     25   prob2      algo     1 #> 26:     26   prob2      algo     4 #> 27:     27   prob2      algo     4 #>     job.id problem algorithm chunk ids[, chunk := .GRP, by = c(\"problem\", \"chunk\")] #> Key: <job.id> #>     job.id problem algorithm chunk #>      <int>  <char>    <char> <int> #>  1:      1   prob1      algo     1 #>  2:      2   prob1      algo     1 #>  3:      3   prob1      algo     2 #>  4:      4   prob1      algo     2 #>  5:      5   prob1      algo     1 #>  6:      6   prob1      algo     2 #>  7:      7   prob1      algo     1 #>  8:      8   prob1      algo     1 #>  9:      9   prob1      algo     2 #> 10:     10   prob2      algo     3 #> 11:     11   prob2      algo     4 #> 12:     12   prob2      algo     4 #> 13:     13   prob2      algo     5 #> 14:     14   prob2      algo     5 #> 15:     15   prob2      algo     5 #> 16:     16   prob2      algo     3 #> 17:     17   prob2      algo     3 #> 18:     18   prob2      algo     3 #> 19:     19   prob2      algo     3 #> 20:     20   prob2      algo     6 #> 21:     21   prob2      algo     4 #> 22:     22   prob2      algo     4 #> 23:     23   prob2      algo     5 #> 24:     24   prob2      algo     6 #> 25:     25   prob2      algo     4 #> 26:     26   prob2      algo     6 #> 27:     27   prob2      algo     6 #>     job.id problem algorithm chunk dcast(ids, chunk ~ problem) #> Using 'chunk' as value column. Use 'value.var' to override #> Warning: 'fun.aggregate' is NULL, but found duplicate row/column combinations, so defaulting to length(). That is, the variables [chunk, problem] used in 'formula' do not uniquely identify rows in the input 'data'. In such cases, 'fun.aggregate' is used to derive a single representative value for each combination in the output data.table, for example by summing or averaging (fun.aggregate=sum or fun.aggregate=mean, respectively). Check the resulting table for values larger than 1 to see which combinations were not unique. See ?dcast.data.table for more details. #> Key: <chunk> #>    chunk prob1 prob2 #>    <int> <int> <int> #> 1:     1     5     0 #> 2:     2     4     0 #> 3:     3     0     5 #> 4:     4     0     5 #> 5:     5     0     4 #> 6:     6     0     4"},{"path":"https://batchtools.mlr-org.com/dev/reference/clearRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove All Jobs — clearRegistry","title":"Remove All Jobs — clearRegistry","text":"Removes jobs registry calls sweepRegistry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/clearRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove All Jobs — clearRegistry","text":"","code":"clearRegistry(reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/clearRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove All Jobs — clearRegistry","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/doJobCollection.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute Jobs of a JobCollection — doJobCollection","title":"Execute Jobs of a JobCollection — doJobCollection","text":"Executes every job JobCollection. function intended called slave.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/doJobCollection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute Jobs of a JobCollection — doJobCollection","text":"","code":"doJobCollection(jc, output = NULL)"},{"path":"https://batchtools.mlr-org.com/dev/reference/doJobCollection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute Jobs of a JobCollection — doJobCollection","text":"jc [JobCollection] Either object class “JobCollection” returned makeJobCollection string path file containing “JobCollection” RDS file (stored submitJobs). output [character(1)] Path file write output . Defaults NULL means output written active sink. set scheduler redirects output log file.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/doJobCollection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute Jobs of a JobCollection — doJobCollection","text":"[character(1)]: Hash JobCollection executed.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/doJobCollection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute Jobs of a JobCollection — doJobCollection","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(identity, 1:2, reg = tmp) #> Adding 2 jobs ... jc = makeJobCollection(1:2, reg = tmp) doJobCollection(jc) #> ### [bt]: This is batchtools v0.9.17.9000 #> ### [bt]: Starting calculation of 2 jobs #> ### [bt]: Setting working directory to '/home/runner/work/batchtools/batchtools/docs/dev/reference' #> ### [bt]: Memory measurement disabled #> ### [bt]: Starting job [batchtools job.id=1] #> ### [bt]: Setting seed to 1166 ... #>  #> ### [bt]: Job terminated successfully [batchtools job.id=1] #> ### [bt]: Starting job [batchtools job.id=2] #> ### [bt]: Setting seed to 1167 ... #>  #> ### [bt]: Job terminated successfully [batchtools job.id=2] #> ### [bt]: Calculation finished!"},{"path":"https://batchtools.mlr-org.com/dev/reference/estimateRuntimes.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Remaining Runtimes — estimateRuntimes","title":"Estimate Remaining Runtimes — estimateRuntimes","text":"Estimates runtimes jobs using random forest implemented ranger. Observed runtimes retrieved Registry runtimes predicted unfinished jobs. estimated remaining time calculated print method. may also pass n determine number parallel jobs used simple Longest Processing Time (LPT) algorithm give estimate parallel runtime.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/estimateRuntimes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Remaining Runtimes — estimateRuntimes","text":"","code":"estimateRuntimes(tab, ..., reg = getDefaultRegistry())  # S3 method for class 'RuntimeEstimate' print(x, n = 1L, ...)"},{"path":"https://batchtools.mlr-org.com/dev/reference/estimateRuntimes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Remaining Runtimes — estimateRuntimes","text":"tab [data.table] Table column “job.id” additional columns predict runtime. Observed runtimes looked registry serve dependent variable. columns tab except “job.id” passed ranger independent variables fit model. ... [] Additional parameters passed ranger. Ignored print method. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry). x [RuntimeEstimate] Object print. n [integer(1)] Number parallel jobs assume runtime estimation.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/estimateRuntimes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Remaining Runtimes — estimateRuntimes","text":"[RuntimeEstimate] list two named elements:  “runtimes” data.table columns “job.id”,  “runtime” (seconds) “type” (“estimated” runtime estimated,  “observed” runtime observed).  element list named “model”] contains fitted random forest object.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/estimateRuntimes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Remaining Runtimes — estimateRuntimes","text":"","code":"# Create a simple toy registry set.seed(1) tmp = makeExperimentRegistry(file.dir = NA, make.default = FALSE, seed = 1) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' addProblem(name = \"iris\", data = iris, fun = function(data, ...) nrow(data), reg = tmp) #> Adding problem 'iris' addAlgorithm(name = \"nrow\", function(instance, ...) nrow(instance), reg = tmp) #> Adding algorithm 'nrow' addAlgorithm(name = \"ncol\", function(instance, ...) ncol(instance), reg = tmp) #> Adding algorithm 'ncol' addExperiments(algo.designs = list(nrow = data.table::CJ(x = 1:50, y = letters[1:5])), reg = tmp) #> Adding 250 experiments ('iris'[1] x 'nrow'[250] x repls[1]) ... addExperiments(algo.designs = list(ncol = data.table::CJ(x = 1:50, y = letters[1:5])), reg = tmp) #> Adding 250 experiments ('iris'[1] x 'ncol'[250] x repls[1]) ...  # We use the job parameters to predict runtimes tab = unwrap(getJobPars(reg = tmp))  # First we need to submit some jobs so that the forest can train on some data. # Thus, we just sample some jobs from the registry while grouping by factor variables. library(data.table) ids = tab[, .SD[sample(nrow(.SD), 5)], by = c(\"problem\", \"algorithm\", \"y\")] setkeyv(ids, \"job.id\") submitJobs(ids, reg = tmp) #> Submitting 50 jobs in 50 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE  # We \"simulate\" some more realistic runtimes here to demonstrate the functionality: # - Algorithm \"ncol\" is 5 times more expensive than \"nrow\" # - x has no effect on the runtime # - If y is \"a\" or \"b\", the runtimes are really high runtime = function(algorithm, x, y) {   ifelse(algorithm == \"nrow\", 100L, 500L) + 1000L * (y %in% letters[1:2]) } tmp$status[ids, done := done + tab[ids, runtime(algorithm, x, y)]] #> Key: <job.id> #>      job.id def.id  submitted    started       done  error mem.used resource.id #>       <int>  <int>      <num>      <num>      <num> <char>    <num>       <int> #>   1:      1      1         NA         NA         NA   <NA>       NA          NA #>   2:      2      2         NA         NA         NA   <NA>       NA          NA #>   3:      3      3         NA         NA         NA   <NA>       NA          NA #>   4:      4      4         NA         NA         NA   <NA>       NA          NA #>   5:      5      5         NA         NA         NA   <NA>       NA          NA #>  ---                                                                            #> 496:    496    496         NA         NA         NA   <NA>       NA          NA #> 497:    497    497         NA         NA         NA   <NA>       NA          NA #> 498:    498    498         NA         NA         NA   <NA>       NA          NA #> 499:    499    499 1747924755 1747924755 1747925255   <NA>       NA           1 #> 500:    500    500         NA         NA         NA   <NA>       NA          NA #>           batch.id log.file                            job.hash job.name  repl #>             <char>   <char>                              <char>   <char> <int> #>   1:          <NA>     <NA>                                <NA>     <NA>     1 #>   2:          <NA>     <NA>                                <NA>     <NA>     1 #>   3:          <NA>     <NA>                                <NA>     <NA>     1 #>   4:          <NA>     <NA>                                <NA>     <NA>     1 #>   5:          <NA>     <NA>                                <NA>     <NA>     1 #>  ---                                                                           #> 496:          <NA>     <NA>                                <NA>     <NA>     1 #> 497:          <NA>     <NA>                                <NA>     <NA>     1 #> 498:          <NA>     <NA>                                <NA>     <NA>     1 #> 499: cfInteractive     <NA> job7e7c20b6dfc51fbb713547bfecdcf52d     <NA>     1 #> 500:          <NA>     <NA>                                <NA>     <NA>     1 rjoin(sjoin(tab, ids), getJobStatus(ids, reg = tmp)[, c(\"job.id\", \"time.running\")]) #> Key: <job.id> #>     job.id problem algorithm     x      y   time.running #>      <int>  <char>    <char> <int> <char>     <difftime> #>  1:     32    iris      nrow     7      b 1100.0336 secs #>  2:     42    iris      nrow     9      b 1100.0336 secs #>  3:     47    iris      nrow    10      b 1100.0333 secs #>  4:     66    iris      nrow    14      a 1100.0335 secs #>  5:     73    iris      nrow    15      c  100.0339 secs #>  6:     75    iris      nrow    15      e  100.0350 secs #>  7:     86    iris      nrow    18      a 1100.0329 secs #>  8:    100    iris      nrow    20      e  100.0328 secs #>  9:    101    iris      nrow    21      a 1100.0329 secs #> 10:    103    iris      nrow    21      c  100.0335 secs #> 11:    123    iris      nrow    25      c  100.0335 secs #> 12:    125    iris      nrow    25      e  100.0336 secs #> 13:    161    iris      nrow    33      a 1100.0330 secs #> 14:    165    iris      nrow    33      e  100.0328 secs #> 15:    169    iris      nrow    34      d  100.0329 secs #> 16:    183    iris      nrow    37      c  100.0371 secs #> 17:    184    iris      nrow    37      d  100.0333 secs #> 18:    203    iris      nrow    41      c  100.0337 secs #> 19:    207    iris      nrow    42      b 1100.0329 secs #> 20:    209    iris      nrow    42      d  100.0330 secs #> 21:    220    iris      nrow    44      e  100.0328 secs #> 22:    227    iris      nrow    46      b 1100.0335 secs #> 23:    229    iris      nrow    46      d  100.0333 secs #> 24:    231    iris      nrow    47      a 1100.0338 secs #> 25:    244    iris      nrow    49      d  100.0329 secs #> 26:    260    iris      ncol     2      e  500.0351 secs #> 27:    276    iris      ncol     6      a 1500.0328 secs #> 28:    278    iris      ncol     6      c  500.0334 secs #> 29:    279    iris      ncol     6      d  500.0334 secs #> 30:    296    iris      ncol    10      a 1500.0336 secs #> 31:    320    iris      ncol    14      e  500.0330 secs #> 32:    340    iris      ncol    18      e  500.0326 secs #> 33:    347    iris      ncol    20      b 1500.0328 secs #> 34:    363    iris      ncol    23      c  500.0334 secs #> 35:    369    iris      ncol    24      d  500.0334 secs #> 36:    373    iris      ncol    25      c  500.0337 secs #> 37:    387    iris      ncol    28      b 1500.0330 secs #> 38:    410    iris      ncol    32      e  500.0327 secs #> 39:    421    iris      ncol    35      a 1500.0330 secs #> 40:    436    iris      ncol    38      a 1500.0338 secs #> 41:    444    iris      ncol    39      d  500.0332 secs #> 42:    448    iris      ncol    40      c  500.0336 secs #> 43:    456    iris      ncol    42      a 1500.0330 secs #> 44:    459    iris      ncol    42      d  500.0329 secs #> 45:    467    iris      ncol    44      b 1500.0365 secs #> 46:    468    iris      ncol    44      c  500.0335 secs #> 47:    475    iris      ncol    45      e  500.0334 secs #> 48:    482    iris      ncol    47      b 1500.0338 secs #> 49:    492    iris      ncol    49      b 1500.0328 secs #> 50:    499    iris      ncol    50      d  500.0329 secs #>     job.id problem algorithm     x      y   time.running  # Estimate runtimes: est = estimateRuntimes(tab, reg = tmp) print(est) #> Runtime Estimate for 500 jobs with 1 CPUs #>   Done     : 0d 09h 43m 21.7s #>   Remaining: 3d 17h 37m 39.8s #>   Total    : 4d 03h 21m 1.4s rjoin(tab, est$runtimes) #> Key: <job.id> #>      job.id problem algorithm     x      y      type   runtime #>       <int>  <char>    <char> <int> <char>    <fctr>     <num> #>   1:      1    iris      nrow     1      a estimated 1106.0471 #>   2:      2    iris      nrow     1      b estimated 1090.0015 #>   3:      3    iris      nrow     1      c estimated  337.9606 #>   4:      4    iris      nrow     1      d estimated  319.5995 #>   5:      5    iris      nrow     1      e estimated  319.0836 #>  ---                                                           #> 496:    496    iris      ncol    50      a estimated 1382.7474 #> 497:    497    iris      ncol    50      b estimated 1389.9974 #> 498:    498    iris      ncol    50      c estimated  615.8907 #> 499:    499    iris      ncol    50      d  observed  500.0329 #> 500:    500    iris      ncol    50      e estimated  576.8826 print(est, n = 10) #> Runtime Estimate for 500 jobs with 10 CPUs #>   Done     : 0d 09h 43m 21.7s #>   Remaining: 3d 17h 37m 39.8s #>   Parallel : 0d 08h 58m 26.8s #>   Total    : 4d 03h 21m 1.4s  # Submit jobs with longest runtime first: ids = est$runtimes[type == \"estimated\"][order(runtime, decreasing = TRUE)] print(ids) #>      job.id      type   runtime #>       <int>    <fctr>     <num> #>   1:    466 estimated 1421.9248 #>   2:    461 estimated 1418.5312 #>   3:    472 estimated 1416.2585 #>   4:    462 estimated 1415.7448 #>   5:    487 estimated 1415.1163 #>  ---                            #> 446:    164 estimated  133.7307 #> 447:    185 estimated  133.4604 #> 448:    174 estimated  131.3807 #> 449:    204 estimated  131.2193 #> 450:    179 estimated  130.2342 if (FALSE) { # \\dontrun{ submitJobs(ids, reg = tmp) } # }  # Group jobs into chunks with runtime < 1h ids = est$runtimes[type == \"estimated\"] ids[, chunk := binpack(runtime, 3600)] #> Key: <job.id> #>      job.id      type   runtime chunk #>       <int>    <fctr>     <num> <int> #>   1:      1 estimated 1106.0471    47 #>   2:      2 estimated 1090.0015    51 #>   3:      3 estimated  337.9606    55 #>   4:      4 estimated  319.5995    33 #>   5:      5 estimated  319.0836    70 #>  ---                                  #> 446:    495 estimated  584.6172    15 #> 447:    496 estimated 1382.7474    19 #> 448:    497 estimated 1389.9974    14 #> 449:    498 estimated  615.8907     4 #> 450:    500 estimated  576.8826    22 print(ids) #> Key: <job.id> #>      job.id      type   runtime chunk #>       <int>    <fctr>     <num> <int> #>   1:      1 estimated 1106.0471    47 #>   2:      2 estimated 1090.0015    51 #>   3:      3 estimated  337.9606    55 #>   4:      4 estimated  319.5995    33 #>   5:      5 estimated  319.0836    70 #>  ---                                  #> 446:    495 estimated  584.6172    15 #> 447:    496 estimated 1382.7474    19 #> 448:    497 estimated 1389.9974    14 #> 449:    498 estimated  615.8907     4 #> 450:    500 estimated  576.8826    22 print(ids[, list(runtime = sum(runtime)), by = chunk]) #>     chunk  runtime #>     <int>    <num> #>  1:    47 3493.812 #>  2:    51 3593.480 #>  3:    55 3585.769 #>  4:    33 3597.824 #>  5:    70 3491.432 #>  6:    48 3489.803 #>  7:    56 3575.456 #>  8:    34 3593.823 #>  9:    71 3488.682 #> 10:    52 3597.187 #> 11:    57 3568.154 #> 12:    72 3484.530 #> 13:    58 3558.669 #> 14:    69 3493.458 #> 15:    73 3479.013 #> 16:    46 3518.298 #> 17:    50 3599.657 #> 18:    38 3596.206 #> 19:    64 3516.009 #> 20:    39 3595.294 #> 21:    63 3519.243 #> 22:    65 3513.059 #> 23:    43 3578.941 #> 24:    36 3599.703 #> 25:    61 3533.437 #> 26:    40 3598.365 #> 27:    37 3595.139 #> 28:    54 3589.486 #> 29:    49 3483.679 #> 30:    42 3584.057 #> 31:    59 3549.053 #> 32:    62 3529.134 #> 33:    41 3587.238 #> 34:    53 3599.601 #> 35:    60 3539.266 #> 36:    44 3546.013 #> 37:    35 3596.856 #> 38:    67 3505.365 #> 39:    45 3545.213 #> 40:    66 3508.753 #> 41:    68 3502.879 #> 42:    27 3597.159 #> 43:    24 3596.792 #> 44:    26 3585.269 #> 45:    25 3599.237 #> 46:    28 3571.554 #> 47:    23 3599.921 #> 48:    74 3473.566 #> 49:    75 3599.812 #> 50:    12 3562.623 #> 51:     8 3593.418 #> 52:    31 3599.629 #> 53:    20 3520.097 #> 54:     7 3596.481 #> 55:    11 3564.663 #> 56:     5 3593.564 #> 57:     6 3596.080 #> 58:    32 3599.959 #> 59:    10 3578.636 #> 60:     4 3597.817 #> 61:    81 3482.714 #> 62:     3 3599.966 #> 63:    83 3599.696 #> 64:    77 3527.579 #> 65:    79 3505.632 #> 66:    76 3591.969 #> 67:    85 3591.238 #> 68:    91 2163.075 #> 69:    82 3470.857 #> 70:    78 3513.407 #> 71:    89 3551.761 #> 72:    88 3560.164 #> 73:    87 3569.921 #> 74:     2 3599.757 #> 75:    80 3493.775 #> 76:    86 3579.504 #> 77:     1 3599.486 #> 78:    84 3599.447 #> 79:    90 3530.690 #> 80:     9 3589.667 #> 81:    22 3597.230 #> 82:    18 3566.949 #> 83:    15 3588.359 #> 84:    21 3599.328 #> 85:    19 3564.289 #> 86:    16 3586.779 #> 87:    30 3552.530 #> 88:    17 3574.283 #> 89:    29 3565.012 #> 90:    13 3599.801 #> 91:    14 3597.568 #>     chunk  runtime if (FALSE) { # \\dontrun{ submitJobs(ids, reg = tmp) } # }  # Group jobs into 10 chunks with similar runtime ids = est$runtimes[type == \"estimated\"] ids[, chunk := lpt(runtime, 10)] #> Key: <job.id> #>      job.id      type   runtime chunk #>       <int>    <fctr>     <num> <int> #>   1:      1 estimated 1106.0471     5 #>   2:      2 estimated 1090.0015     8 #>   3:      3 estimated  337.9606     2 #>   4:      4 estimated  319.5995    10 #>   5:      5 estimated  319.0836     1 #>  ---                                  #> 446:    495 estimated  584.6172     5 #> 447:    496 estimated 1382.7474     9 #> 448:    497 estimated 1389.9974     4 #> 449:    498 estimated  615.8907     1 #> 450:    500 estimated  576.8826     5 print(ids[, list(runtime = sum(runtime)), by = chunk]) #>     chunk  runtime #>     <int>    <num> #>  1:     5 32306.40 #>  2:     8 32230.15 #>  3:     2 32306.83 #>  4:    10 32234.45 #>  5:     1 32295.78 #>  6:     4 32227.75 #>  7:     9 32295.66 #>  8:     7 32228.63 #>  9:     3 32306.41 #> 10:     6 32227.70"},{"path":"https://batchtools.mlr-org.com/dev/reference/execJob.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a Single Jobs — execJob","title":"Execute a Single Jobs — execJob","text":"Executes single job (created makeJob) returns result. Also works Experiments.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/execJob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute a Single Jobs — execJob","text":"","code":"execJob(job)"},{"path":"https://batchtools.mlr-org.com/dev/reference/execJob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a Single Jobs — execJob","text":"job [Job | Experiment] Job/Experiment execute.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/execJob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute a Single Jobs — execJob","text":"Result job.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/execJob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute a Single Jobs — execJob","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(identity, 1:2, reg = tmp) #> Adding 2 jobs ... job = makeJob(1, reg = tmp) execJob(job) #> ### [bt]: Setting seed to 12825 ... #> [1] 1"},{"path":"https://batchtools.mlr-org.com/dev/reference/findConfFile.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a batchtools Configuration File — findConfFile","title":"Find a batchtools Configuration File — findConfFile","text":"functions returns path first configuration file found following locations: File “batchtools.conf.R” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. File “batchtools.conf.R” current working directory. File “config.R” user configuration directory reported rappdirs::user_config_dir(\"batchtools\", expand = FALSE) (depending OS, e.g., linux usually resolves “~/.config/batchtools/config.R”). “.batchtools.conf.R” home directory (“~”). “config.R” site config directory reported rappdirs::site_config_dir(\"batchtools\") (depending OS). file can used admins set sane defaults computation site.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/findConfFile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a batchtools Configuration File — findConfFile","text":"","code":"findConfFile()"},{"path":"https://batchtools.mlr-org.com/dev/reference/findConfFile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find a batchtools Configuration File — findConfFile","text":"[character(1)] Path configuration file NA configuration file found.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/findJobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Find and Filter Jobs — findJobs","title":"Find and Filter Jobs — findJobs","text":"functions used find filter jobs, depending either parameters (findJobs findExperiments), tags (findTagged), computational status (functions, see getStatus overview). Note findQueued, findRunning, findOnSystem findExpired somewhat heuristic may report misleading results, depending state system ClusterFunctions implementation. See JoinTables convenient set operations (unions, intersects, differences) tables job ids.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/findJobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find and Filter Jobs — findJobs","text":"","code":"findJobs(expr, ids = NULL, reg = getDefaultRegistry())  findExperiments(   ids = NULL,   prob.name = NA_character_,   prob.pattern = NA_character_,   algo.name = NA_character_,   algo.pattern = NA_character_,   prob.pars,   algo.pars,   repls = NULL,   reg = getDefaultRegistry() )  findSubmitted(ids = NULL, reg = getDefaultRegistry())  findNotSubmitted(ids = NULL, reg = getDefaultRegistry())  findStarted(ids = NULL, reg = getDefaultRegistry())  findNotStarted(ids = NULL, reg = getDefaultRegistry())  findDone(ids = NULL, reg = getDefaultRegistry())  findNotDone(ids = NULL, reg = getDefaultRegistry())  findErrors(ids = NULL, reg = getDefaultRegistry())  findOnSystem(ids = NULL, reg = getDefaultRegistry())  findRunning(ids = NULL, reg = getDefaultRegistry())  findQueued(ids = NULL, reg = getDefaultRegistry())  findExpired(ids = NULL, reg = getDefaultRegistry())  findTagged(tags = character(0L), ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/findJobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find and Filter Jobs — findJobs","text":"expr [expression] Predicate expression evaluated job parameters. Jobs expr evaluates TRUE returned. ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry). prob.name [character] Exact name problem (substring matching). provided, problems matched. prob.pattern [character] Regular expression pattern match problem names. provided, problems matched. algo.name [character] Exact name problem (substring matching). provided, algorithms matched. algo.pattern [character] Regular expression pattern match algorithm names. provided, algorithms matched. prob.pars [expression] Predicate expression evaluated problem parameters. algo.pars [expression] Predicate expression evaluated algorithm parameters. repls [integer] Whitelist replication numbers. provided, replications matched. tags [character] Return jobs tagged tags provided.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/findJobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find and Filter Jobs — findJobs","text":"[data.table] column “job.id” containing matched jobs.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/findJobs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find and Filter Jobs — findJobs","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(identity, i = 1:3, reg = tmp) #> Adding 3 jobs ... ids = findNotSubmitted(reg = tmp)  # get all jobs: findJobs(reg = tmp) #> Key: <job.id> #>    job.id #>     <int> #> 1:      1 #> 2:      2 #> 3:      3  # filter for jobs with parameter i >= 2 findJobs(i >= 2, reg = tmp)  # filter on the computational status findSubmitted(reg = tmp) #> Key: <job.id> #> Empty data.table (0 rows and 1 cols): job.id findNotDone(reg = tmp) #> Key: <job.id> #>    job.id #>     <int> #> 1:      1 #> 2:      2 #> 3:      3  # filter on tags addJobTags(2:3, \"my_tag\", reg = tmp) findTagged(tags = \"my_tag\", reg = tmp) #> Key: <job.id> #>    job.id #>     <int> #> 1:      2 #> 2:      3  # combine filter functions using joins # -> jobs which are not done and not tagged (using an anti-join): ajoin(findNotDone(reg = tmp), findTagged(\"my_tag\", reg = tmp)) #> Key: <job.id> #>    job.id #>     <int> #> 1:      1"},{"path":"https://batchtools.mlr-org.com/dev/reference/findTemplateFile.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a batchtools Template File — findTemplateFile","title":"Find a batchtools Template File — findTemplateFile","text":"functions returns path template file file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/findTemplateFile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a batchtools Template File — findTemplateFile","text":"","code":"findTemplateFile(template)"},{"path":"https://batchtools.mlr-org.com/dev/reference/findTemplateFile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find a batchtools Template File — findTemplateFile","text":"template [character(1)] Either path brew template file (extension “tmpl”), short descriptive name enabling following heuristic file lookup: “batchtools.[template].tmpl” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. “batchtools.[template].tmpl” current working directory. “[template].tmpl” user config directory (see user_config_dir); linux usually “~/.config/batchtools/[template].tmpl”. “.batchtools.[template].tmpl” home directory. “[template].tmpl” package installation directory subfolder “templates”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/findTemplateFile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find a batchtools Template File — findTemplateFile","text":"[character] Path file NA template template file found.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getDefaultRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and Set the Default Registry — getDefaultRegistry","title":"Get and Set the Default Registry — getDefaultRegistry","text":"getDefaultRegistry returns registry currently set default (stops exception none set). setDefaultRegistry sets registry default.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getDefaultRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and Set the Default Registry — getDefaultRegistry","text":"","code":"getDefaultRegistry()  setDefaultRegistry(reg)"},{"path":"https://batchtools.mlr-org.com/dev/reference/getDefaultRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and Set the Default Registry — getDefaultRegistry","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/getErrorMessages.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Error Messages — getErrorMessages","title":"Retrieve Error Messages — getErrorMessages","text":"Extracts error messages internal data base returns table.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getErrorMessages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Error Messages — getErrorMessages","text":"","code":"getErrorMessages(   ids = NULL,   missing.as.error = FALSE,   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/getErrorMessages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Error Messages — getErrorMessages","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findErrors. Invalid ids ignored. missing..error [logical(1)] Treat missing results errors? TRUE, error message “[terminated]” imputed jobs terminated. Default FALSE reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getErrorMessages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Error Messages — getErrorMessages","text":"[data.table] columns “job.id”, “terminated” (logical),   “error” (logical) “message” (string).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/getErrorMessages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Error Messages — getErrorMessages","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' fun = function(i) if (i == 3) stop(i) else i ids = batchMap(fun, i = 1:5, reg = tmp) #> Adding 5 jobs ... submitJobs(1:4, reg = tmp) #> Submitting 4 jobs in 4 chunks using cluster functions 'Interactive' ... #> Error in (function (i)  : 3 waitForJobs(1:4, reg = tmp) #> [1] FALSE getErrorMessages(ids, reg = tmp) #> Key: <job.id> #>    job.id terminated  error                     message #>     <int>     <lgcl> <lgcl>                      <char> #> 1:      1       TRUE  FALSE                        <NA> #> 2:      2       TRUE  FALSE                        <NA> #> 3:      3       TRUE   TRUE Error in (function (i)  : 3 #> 4:      4       TRUE  FALSE                        <NA> #> 5:      5      FALSE  FALSE                        <NA> getErrorMessages(ids, missing.as.error = TRUE, reg = tmp) #> Key: <job.id> #>    job.id terminated  error                     message #>     <int>     <lgcl> <lgcl>                      <char> #> 1:      1       TRUE  FALSE                        <NA> #> 2:      2       TRUE  FALSE                        <NA> #> 3:      3       TRUE   TRUE Error in (function (i)  : 3 #> 4:      4       TRUE  FALSE                        <NA> #> 5:      5      FALSE   TRUE            [not terminated]"},{"path":"https://batchtools.mlr-org.com/dev/reference/getJobTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Query Job Information — getJobTable","title":"Query Job Information — getJobTable","text":"getJobStatus returns internal table stores information computational status jobs, getJobPars table job parameters, getJobResources table resources set submit jobs, getJobTags tags jobs (see Tags). getJobTable returns tables joined.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getJobTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query Job Information — getJobTable","text":"","code":"getJobTable(ids = NULL, reg = getDefaultRegistry())  getJobStatus(ids = NULL, reg = getDefaultRegistry())  getJobResources(ids = NULL, reg = getDefaultRegistry())  getJobPars(ids = NULL, reg = getDefaultRegistry())  getJobTags(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/getJobTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query Job Information — getJobTable","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getJobTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query Job Information — getJobTable","text":"[data.table] following columns (necessarily order): job.id Unique Job ID integer. submitted Time job submitted batch system POSIXct. started Time job started batch system POSIXct. done Time job terminated (successfully error) POSIXct. error Either NA job terminated successfully error message. mem.used Estimate memory usage. batch.id Batch ID reported scheduler. log.file Log file. missing, defaults [job.hash].log. job.hash Unique string identifying job chunk. time.queued Time seconds (difftime) job queued. time.running Time seconds (difftime) job running. pars List parameters/arguments job. resources List computational resources set job. tags Tags joined string, delimited “,”. problem ExperimentRegistry: problem identifier. algorithm ExperimentRegistry: algorithm identifier.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getJobTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query Job Information — getJobTable","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' f = function(x) if (x < 0) stop(\"x must be > 0\") else sqrt(x) batchMap(f, x = c(-1, 0, 1), reg = tmp) #> Adding 3 jobs ... submitJobs(reg = tmp) #> Submitting 3 jobs in 3 chunks using cluster functions 'Interactive' ... #> Error in (function (x)  : x must be > 0 waitForJobs(reg = tmp) #> [1] FALSE addJobTags(1:2, \"tag1\", reg = tmp) addJobTags(2, \"tag2\", reg = tmp)  # Complete table: getJobTable(reg = tmp) #> Key: <job.id> #>    job.id           submitted             started                done #>     <int>              <POSc>              <POSc>              <POSc> #> 1:      1 2025-05-22 14:39:18 2025-05-22 14:39:18 2025-05-22 14:39:18 #> 2:      2 2025-05-22 14:39:18 2025-05-22 14:39:18 2025-05-22 14:39:19 #> 3:      3 2025-05-22 14:39:19 2025-05-22 14:39:19 2025-05-22 14:39:19 #>                                      error mem.used      batch.id log.file #>                                     <char>    <num>        <char>   <char> #> 1: Error in (function (x)  : x must be > 0       NA cfInteractive     <NA> #> 2:                                    <NA>       NA cfInteractive     <NA> #> 3:                                    <NA>       NA cfInteractive     <NA> #>                               job.hash job.name      time.queued   time.running #>                                 <char>   <char>       <difftime>     <difftime> #> 1: joba6b3bcbeaa3033f45caf30600f8c9911     <NA> 0.003800154 secs 0.2057998 secs #> 2: job9c098dca23c22799d8f0ebe662592e8d     <NA> 0.003799915 secs 0.2039001 secs #> 3: job64e0a1ee1cf42528773050e9fc4fc0bf     <NA> 0.003799915 secs 0.2093000 secs #>     job.pars resources      tags #>       <list>    <list>    <char> #> 1: <list[1]> <list[0]>      tag1 #> 2: <list[1]> <list[0]> tag1,tag2 #> 3: <list[1]> <list[0]>      <NA>  # Job parameters: getJobPars(reg = tmp) #> Key: <job.id> #>    job.id  job.pars #>     <int>    <list> #> 1:      1 <list[1]> #> 2:      2 <list[1]> #> 3:      3 <list[1]>  # Set and retrieve tags: getJobTags(reg = tmp) #> Key: <job.id> #>    job.id      tags #>     <int>    <char> #> 1:      1      tag1 #> 2:      2 tag1,tag2 #> 3:      3      <NA>  # Job parameters with tags right-joined: rjoin(getJobPars(reg = tmp), getJobTags(reg = tmp)) #> Key: <job.id> #>    job.id  job.pars      tags #>     <int>    <list>    <char> #> 1:      1 <list[1]>      tag1 #> 2:      2 <list[1]> tag1,tag2 #> 3:      3 <list[1]>      <NA>"},{"path":"https://batchtools.mlr-org.com/dev/reference/getStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the Computational Status — getStatus","title":"Summarize the Computational Status — getStatus","text":"function gives encompassing overview computational status system. status can one many following: “defined”: Jobs defined via batchMap addExperiments, yet submitted. “submitted”: Jobs submitted batch system via submitJobs, scheduled execution. “started”: Jobs started. “done”: Jobs terminated successfully. “error”: Jobs terminated exception. “running”: Jobs listed cluster functions running live system. supported cluster functions. “queued”: Jobs listed cluster functions queued live system. supported cluster functions. “system”: Jobs listed cluster functions queued running. supported cluster functions. “expired”: Jobs submitted, vanished live system. Note determined heuristically may include false positives. , job terminated successfully counts towards jobs submitted, started done. retrieve corresponding job ids, see findJobs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the Computational Status — getStatus","text":"","code":"getStatus(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/getStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the Computational Status — getStatus","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/getStatus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the Computational Status — getStatus","text":"[data.table] (class “Status” printing).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/getStatus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize the Computational Status — getStatus","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' fun = function(i) if (i == 3) stop(i) else i ids = batchMap(fun, i = 1:5, reg = tmp) #> Adding 5 jobs ... submitJobs(ids = 1:4, reg = tmp) #> Submitting 4 jobs in 4 chunks using cluster functions 'Interactive' ... #> Error in (function (i)  : 3 waitForJobs(reg = tmp) #> [1] FALSE  tab = getStatus(reg = tmp) print(tab) #> Status for 5 jobs at 2025-05-22 14:39:20: #>   Submitted    : 4 ( 80.0%) #>   -- Queued    : 0 (  0.0%) #>   -- Started   : 4 ( 80.0%) #>   ---- Running : 0 (  0.0%) #>   ---- Done    : 3 ( 60.0%) #>   ---- Error   : 1 ( 20.0%) #>   ---- Expired : 0 (  0.0%) str(tab) #> Classes ‘Status’, ‘data.table’ and 'data.frame':\t1 obs. of  9 variables: #>  $ defined  : int 5 #>  $ submitted: int 4 #>  $ started  : int 4 #>  $ done     : int 3 #>  $ error    : int 1 #>  $ queued   : int 0 #>  $ running  : int 0 #>  $ expired  : int 0 #>  $ system   : int 0 #>  - attr(*, \".internal.selfref\")=<externalptr>"},{"path":"https://batchtools.mlr-org.com/dev/reference/grepLogs.html","id":null,"dir":"Reference","previous_headings":"","what":"Grep Log Files for a Pattern — grepLogs","title":"Grep Log Files for a Pattern — grepLogs","text":"Crawls log files reports jobs lines matching pattern. See showLog example.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/grepLogs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grep Log Files for a Pattern — grepLogs","text":"","code":"grepLogs(   ids = NULL,   pattern,   ignore.case = FALSE,   fixed = FALSE,   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/grepLogs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grep Log Files for a Pattern — grepLogs","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findStarted. Invalid ids ignored. pattern [character(1L)] Regular expression string (see fixed). ignore.case [logical(1L)] TRUE match performed case insensitively. fixed [logical(1L)] FALSE (default), pattern regular expression fixed string otherwise. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/grepLogs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grep Log Files for a Pattern — grepLogs","text":"[data.table] columns “job.id” “message”.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/killJobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Kill Jobs — killJobs","title":"Kill Jobs — killJobs","text":"Kill jobs currently running batch system. case error killing, function tries - short sleep - kill remaining batch jobs . fails three times jobs, function gives . Jobs successfully killed reset Registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/killJobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kill Jobs — killJobs","text":"","code":"killJobs(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/killJobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kill Jobs — killJobs","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findOnSystem. Invalid ids ignored. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/killJobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kill Jobs — killJobs","text":"[data.table] columns “job.id”, corresponding “batch.id”   logical flag “killed” indicating success.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/loadRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a Registry from the File System — loadRegistry","title":"Load a Registry from the File System — loadRegistry","text":"Loads registry file.dir. Multiple R sessions accessing registry simultaneously can lead database inconsistencies. especially dangerous file.dir accessed multiple machines, e.g. via mount. just need check status peek preliminary results another process still submitting waiting pending results, can load registry read-mode. operations need change registry raise exception mode. Files communicated back computational nodes parsed update registry memory registry file system remains unchanged. heuristic tries detect registry altered background process case automatically restricts current registry read-mode. However, rely heuristic work flawlessly. Thus, set writeable TRUE absolutely sure state-changing processes terminated. need write access, load registry writeable set TRUE.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/loadRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a Registry from the File System — loadRegistry","text":"","code":"loadRegistry(   file.dir,   work.dir = NULL,   conf.file = findConfFile(),   make.default = TRUE,   writeable = FALSE )"},{"path":"https://batchtools.mlr-org.com/dev/reference/loadRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a Registry from the File System — loadRegistry","text":"file.dir [character(1)]   Path files registry saved.   Default directory “registry” current working directory.   provided path get normalized unless given relative home directory   (.e., starting “~”). Note templates handle relative paths well. pass NA, temporary directory used.   way, can create disposable registries btlapply examples.   default, temporary directory tempdir() used.   want use another directory, e.g. directory shared nodes,   can set configuration file setting variable temp.dir. work.dir [character(1)]   Working directory R process running jobs.   Defaults working directory currently set Registry construction (see getwd).   loadRegistry uses stored work.dir, may also explicitly overwrite ,   e.g., switching another system. provided path get normalized unless given relative home directory   (.e., starting “~”). Note templates handle relative paths well. conf.file [character(1)]   Path configuration file sourced registry created.   configuration file can define batchtools interacts system via ClusterFunctions.   Separating configuration underlying host system R code allows easily move computation another site. file lookup implemented internal (exported) function findConfFile returns first file found following candidates: File “batchtools.conf.R” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. File “batchtools.conf.R” current working directory. File “config.R” user configuration directory reported rappdirs::user_config_dir(\"batchtools\", expand = FALSE) (depending OS, e.g., linux usually resolves “~/.config/batchtools/config.R”). “.batchtools.conf.R” home directory (“~”). “config.R” site config directory reported rappdirs::site_config_dir(\"batchtools\") (depending OS). file can used admins set sane defaults computation site. Set NA want suppress reading configuration file.   configuration file found, gets sourced inside environment registry defaults variables set.   Therefore can set overwrite slots, e.g. default.resources = list(walltime = 3600) set default resources “max.concurrent.jobs”   limit number jobs allowed run simultaneously system. make.default [logical(1)] set TRUE, created registry saved inside package namespace acts default registry. might want switch work multiple registries simultaneously. Default TRUE. writeable [logical(1)] Loads registry read-write mode. Default FALSE.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/loadRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a Registry from the File System — loadRegistry","text":"[Registry].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/loadResult.html","id":null,"dir":"Reference","previous_headings":"","what":"Load the Result of a Single Job — loadResult","title":"Load the Result of a Single Job — loadResult","text":"Loads result single job.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/loadResult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load the Result of a Single Job — loadResult","text":"","code":"loadResult(id, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/loadResult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load the Result of a Single Job — loadResult","text":"id [integer(1) data.table] Single integer specify job data.table column job.id exactly one row. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/loadResult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load the Result of a Single Job — loadResult","text":"[]. stored result.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctions.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions Constructor — makeClusterFunctions","title":"ClusterFunctions Constructor — makeClusterFunctions","text":"constructor used create custom cluster functions. Note standard implementations TORQUE, Slurm, LSF, SGE, etc. ship package.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions Constructor — makeClusterFunctions","text":"","code":"makeClusterFunctions(   name,   submitJob,   killJob = NULL,   listJobsQueued = NULL,   listJobsRunning = NULL,   array.var = NA_character_,   store.job.collection = FALSE,   store.job.files = FALSE,   scheduler.latency = 0,   fs.latency = 0,   hooks = list() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions Constructor — makeClusterFunctions","text":"name [character(1)] Name cluster functions. submitJob [function(reg, jc, ...)] Function submit new jobs. Must return SubmitJobResult object. arguments reg (Registry) jobs (JobCollection). killJob [function(reg, batch.id)] Function kill job batch system. Make sure definitely kill job! Return value currently ignored. Must arguments reg (Registry) batch.id (character(1) returned submitJob). Note helper function cfKillJob repeatedly try kill jobs. Set killJob NULL killing jobs supported. listJobsQueued [function(reg)] List queued jobs batch system current user. Must return character vector batch ids, format returned submitJob. Set listJobsQueued NULL listing queued jobs supported. listJobsRunning [function(reg)] List running jobs batch system current user. Must return character vector batch ids, format returned submitJob. matter return job ids many (e.g. current user instead current registry), include relevant ones. Must argument reg (Registry). Set listJobsRunning NULL listing running jobs supported. array.var [character(1)] Name environment variable set scheduler identify IDs job arrays. Default NA array support. store.job.collection [logical(1)] Flag indicate cluster function implementation submitJob can directly handle JobCollection objects. set FALSE, JobCollection serialized file system submitting job. store.job.files [logical(1)] Flag indicate job files need stored file directory. set FALSE (default), job file created temporary directory, otherwise (debug mode enabled) subdirectory jobs file.dir. scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system. hooks [list] Named list functions called certain events like “pre.submit” “post.sync”. See Hooks.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsDocker.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for Docker — makeClusterFunctionsDocker","title":"ClusterFunctions for Docker — makeClusterFunctionsDocker","text":"Cluster functions Docker/Docker Swarm (https://docs.docker.com/engine/swarm/). submitJob function executes docker [docker.args] run --detach=true [image.args] [resources] [image] [cmd]. Arguments docker.args, image.args image can set construction. resources part takes named resources ncpus memory submitJobs maps arguments --cpu-shares --memory (Megabytes). resource threads mapped environment variables “OMP_NUM_THREADS” “OPENBLAS_NUM_THREADS”. reliably identify jobs swarm, jobs labeled “batchtools=[job.hash]” named using current login name (label “user”) job hash (label “batchtools”). listJobsRunning uses docker [docker.args] ps --format={{.ID}} filter running jobs. killJobs uses docker [docker.args] kill [batch.id] filter running jobs. cluster functions use Hook remove finished jobs new submit every time Registry synchronized (using syncRegistry). currently required docker remove terminated containers automatically. Use docker ps ---filter 'label=batchtools' --filter 'status=exited' identify remove terminated containers manually (usa cron job).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsDocker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for Docker — makeClusterFunctionsDocker","text":"","code":"makeClusterFunctionsDocker(   image,   docker.args = character(0L),   image.args = character(0L),   scheduler.latency = 1,   fs.latency = 65 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsDocker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for Docker — makeClusterFunctionsDocker","text":"image [character(1)] Name docker image run. docker.args [character] Additional arguments passed “docker” ** command (“run”, “ps” “kill”) execute (e.g., docker host). image.args [character] Additional arguments passed “docker run” (e.g., define mounts environment variables). scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsDocker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for Docker — makeClusterFunctionsDocker","text":"[ClusterFunctions].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsInteractive.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for Sequential Execution in the Running R Session — makeClusterFunctionsInteractive","title":"ClusterFunctions for Sequential Execution in the Running R Session — makeClusterFunctionsInteractive","text":"jobs executed sequentially using current R process submitJobs called. Thus, submitJob blocks session job finished. main use ClusterFunctions implementation test debug programs local computer. Listing jobs returns empty vector (jobs can running call ) killJob implemented reasons.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsInteractive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for Sequential Execution in the Running R Session — makeClusterFunctionsInteractive","text":"","code":"makeClusterFunctionsInteractive(   external = FALSE,   write.logs = TRUE,   fs.latency = 0 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsInteractive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for Sequential Execution in the Running R Session — makeClusterFunctionsInteractive","text":"external [logical(1)] set TRUE, jobs started fresh R session instead currently active still waits termination. Default FALSE. write.logs [logical(1)] Sink output log files. Turning logging can increase speed calculations makes difficult debug. Default TRUE. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsInteractive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for Sequential Execution in the Running R Session — makeClusterFunctionsInteractive","text":"[ClusterFunctions].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsLSF.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for LSF Systems — makeClusterFunctionsLSF","title":"ClusterFunctions for LSF Systems — makeClusterFunctionsLSF","text":"Cluster functions LSF (https://www.ibm.com/products/hpc-workload-management). Job files created based brew template template.file. file processed brew submitted queue using bsub command. Jobs killed using bkill command list running jobs retrieved using bjobs -u $USER -w. user must appropriate privileges submit, delete list jobs cluster (usually case). template file can access resources passed submitJobs well variables stored JobCollection. template file's job choose queue job handle desired resource allocations.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsLSF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for LSF Systems — makeClusterFunctionsLSF","text":"","code":"makeClusterFunctionsLSF(   template = \"lsf\",   scheduler.latency = 1,   fs.latency = 65 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsLSF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for LSF Systems — makeClusterFunctionsLSF","text":"template [character(1)] Either path brew template file (extension “tmpl”), short descriptive name enabling following heuristic file lookup: “batchtools.[template].tmpl” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. “batchtools.[template].tmpl” current working directory. “[template].tmpl” user config directory (see user_config_dir); linux usually “~/.config/batchtools/[template].tmpl”. “.batchtools.[template].tmpl” home directory. “[template].tmpl” package installation directory subfolder “templates”. scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsLSF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for LSF Systems — makeClusterFunctionsLSF","text":"[ClusterFunctions].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsLSF.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ClusterFunctions for LSF Systems — makeClusterFunctionsLSF","text":"Array jobs currently supported.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsMulticore.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for Parallel Multicore Execution — makeClusterFunctionsMulticore","title":"ClusterFunctions for Parallel Multicore Execution — makeClusterFunctionsMulticore","text":"Jobs spawned asynchronously using functions mcparallel mccollect (parallel). work Windows, use makeClusterFunctionsSocket instead.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsMulticore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for Parallel Multicore Execution — makeClusterFunctionsMulticore","text":"","code":"makeClusterFunctionsMulticore(ncpus = NA_integer_, fs.latency = 0)"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsMulticore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for Parallel Multicore Execution — makeClusterFunctionsMulticore","text":"ncpus [integer(1)] Number CPUs. Default use logical cores. total number cores \"available\" can set via option mc.cores defaults heuristic implemented detectCores. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsMulticore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for Parallel Multicore Execution — makeClusterFunctionsMulticore","text":"[ClusterFunctions].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsOpenLava.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for OpenLava — makeClusterFunctionsOpenLava","title":"ClusterFunctions for OpenLava — makeClusterFunctionsOpenLava","text":"Cluster functions OpenLava. Job files created based brew template template. file processed brew submitted queue using bsub command. Jobs killed using bkill command list running jobs retrieved using bjobs -u $USER -w. user must appropriate privileges submit, delete list jobs cluster (usually case). template file can access resources passed submitJobs well variables stored JobCollection. template file's job choose queue job handle desired resource allocations.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsOpenLava.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for OpenLava — makeClusterFunctionsOpenLava","text":"","code":"makeClusterFunctionsOpenLava(   template = \"openlava\",   scheduler.latency = 1,   fs.latency = 65 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsOpenLava.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for OpenLava — makeClusterFunctionsOpenLava","text":"template [character(1)] Either path brew template file (extension “tmpl”), short descriptive name enabling following heuristic file lookup: “batchtools.[template].tmpl” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. “batchtools.[template].tmpl” current working directory. “[template].tmpl” user config directory (see user_config_dir); linux usually “~/.config/batchtools/[template].tmpl”. “.batchtools.[template].tmpl” home directory. “[template].tmpl” package installation directory subfolder “templates”. scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsOpenLava.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for OpenLava — makeClusterFunctionsOpenLava","text":"[ClusterFunctions].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsOpenLava.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ClusterFunctions for OpenLava — makeClusterFunctionsOpenLava","text":"Array jobs currently supported.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSGE.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for SGE Systems — makeClusterFunctionsSGE","title":"ClusterFunctions for SGE Systems — makeClusterFunctionsSGE","text":"Cluster functions Univa Grid Engine / Oracle Grid Engine / Sun Grid Engine (https://www.univa.com/). Job files created based brew template template. file processed brew submitted queue using qsub command. Jobs killed using qdel command list running jobs retrieved using qselect. user must appropriate privileges submit, delete list jobs cluster (usually case). template file can access resources passed submitJobs well variables stored JobCollection. template file's job choose queue job handle desired resource allocations.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSGE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for SGE Systems — makeClusterFunctionsSGE","text":"","code":"makeClusterFunctionsSGE(   template = \"sge\",   nodename = \"localhost\",   scheduler.latency = 1,   fs.latency = 65 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSGE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for SGE Systems — makeClusterFunctionsSGE","text":"template [character(1)] Either path brew template file (extension “tmpl”), short descriptive name enabling following heuristic file lookup: “batchtools.[template].tmpl” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. “batchtools.[template].tmpl” current working directory. “[template].tmpl” user config directory (see user_config_dir); linux usually “~/.config/batchtools/[template].tmpl”. “.batchtools.[template].tmpl” home directory. “[template].tmpl” package installation directory subfolder “templates”. nodename [character(1)] Nodename master host. commands send via SSH host. works iff Passwordless authentication (e.g., via SSH public key authentication) set . file directory shared across machines, e.g. mounted via SSHFS. Either absolute path file.dir identical machines, paths provided relative home directory. Symbolic links work. scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSGE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for SGE Systems — makeClusterFunctionsSGE","text":"[ClusterFunctions].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSGE.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ClusterFunctions for SGE Systems — makeClusterFunctionsSGE","text":"Array jobs currently supported.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSSH.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","title":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","text":"Jobs spawned starting multiple R sessions via Rscript SSH. hostname Worker equals “localhost”, Rscript called directly need SSH client installed.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSSH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","text":"","code":"makeClusterFunctionsSSH(workers, fs.latency = 65)"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSSH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","text":"workers [list Worker] List Workers constructed Worker. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSSH.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","text":"[ClusterFunctions].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSSH.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","text":"use custom “.ssh/config” file, make sure ProxyCommand passes ‘-q’ ssh, otherwise output end message “Killed signal 1” break communication nodes.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSSH.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ClusterFunctions for Remote SSH Execution — makeClusterFunctionsSSH","text":"","code":"if (FALSE) { # \\dontrun{ # cluster functions for multicore execution on the local machine makeClusterFunctionsSSH(list(Worker$new(\"localhost\", ncpus = 2))) } # }"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSlurm.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for Slurm Systems — makeClusterFunctionsSlurm","title":"ClusterFunctions for Slurm Systems — makeClusterFunctionsSlurm","text":"Cluster functions Slurm (https://slurm.schedmd.com/). Job files created based brew template template.file. file processed brew submitted queue using sbatch command. Jobs killed using scancel command list running jobs retrieved using squeue. user must appropriate privileges submit, delete list jobs cluster (usually case). template file can access resources passed submitJobs well variables stored JobCollection. template file's job choose queue job handle desired resource allocations. Note might specify cluster name want use default, otherwise commands listing killing jobs work.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSlurm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for Slurm Systems — makeClusterFunctionsSlurm","text":"","code":"makeClusterFunctionsSlurm(   template = \"slurm\",   array.jobs = TRUE,   nodename = \"localhost\",   scheduler.latency = 1,   fs.latency = 65 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSlurm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for Slurm Systems — makeClusterFunctionsSlurm","text":"template [character(1)] Either path brew template file (extension “tmpl”), short descriptive name enabling following heuristic file lookup: “batchtools.[template].tmpl” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. “batchtools.[template].tmpl” current working directory. “[template].tmpl” user config directory (see user_config_dir); linux usually “~/.config/batchtools/[template].tmpl”. “.batchtools.[template].tmpl” home directory. “[template].tmpl” package installation directory subfolder “templates”. array.jobs [logical(1)] array jobs disabled computing site, set FALSE. nodename [character(1)] Nodename master host. commands send via SSH host. works iff Passwordless authentication (e.g., via SSH public key authentication) set . file directory shared across machines, e.g. mounted via SSHFS. Either absolute path file.dir identical machines, paths provided relative home directory. Symbolic links work. scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSlurm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for Slurm Systems — makeClusterFunctionsSlurm","text":"[ClusterFunctions].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSocket.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for Parallel Socket Execution — makeClusterFunctionsSocket","title":"ClusterFunctions for Parallel Socket Execution — makeClusterFunctionsSocket","text":"Jobs spawned asynchronously using package snow.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSocket.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for Parallel Socket Execution — makeClusterFunctionsSocket","text":"","code":"makeClusterFunctionsSocket(ncpus = NA_integer_, fs.latency = 65)"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSocket.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for Parallel Socket Execution — makeClusterFunctionsSocket","text":"ncpus [integer(1)] Number CPUs. Default use logical cores. total number cores \"available\" can set via option mc.cores defaults heuristic implemented detectCores. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsSocket.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for Parallel Socket Execution — makeClusterFunctionsSocket","text":"[ClusterFunctions].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsTORQUE.html","id":null,"dir":"Reference","previous_headings":"","what":"ClusterFunctions for OpenPBS/TORQUE Systems — makeClusterFunctionsTORQUE","title":"ClusterFunctions for OpenPBS/TORQUE Systems — makeClusterFunctionsTORQUE","text":"Cluster functions TORQUE/PBS (https://adaptivecomputing.com/cherry-services/torque-resource-manager/). Job files created based brew template template.file. file processed brew submitted queue using qsub command. Jobs killed using qdel command list running jobs retrieved using qselect. user must appropriate privileges submit, delete list jobs cluster (usually case). template file can access resources passed submitJobs well variables stored JobCollection. template file's job choose queue job handle desired resource allocations.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsTORQUE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ClusterFunctions for OpenPBS/TORQUE Systems — makeClusterFunctionsTORQUE","text":"","code":"makeClusterFunctionsTORQUE(   template = \"torque\",   scheduler.latency = 1,   fs.latency = 65 )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsTORQUE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ClusterFunctions for OpenPBS/TORQUE Systems — makeClusterFunctionsTORQUE","text":"template [character(1)] Either path brew template file (extension “tmpl”), short descriptive name enabling following heuristic file lookup: “batchtools.[template].tmpl” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. “batchtools.[template].tmpl” current working directory. “[template].tmpl” user config directory (see user_config_dir); linux usually “~/.config/batchtools/[template].tmpl”. “.batchtools.[template].tmpl” home directory. “[template].tmpl” package installation directory subfolder “templates”. scheduler.latency [numeric(1)] Time sleep important interactions scheduler ensure sane state. Currently triggered calling submitJobs. fs.latency [numeric(1)] Expected maximum latency file system, seconds. Set positive number network file systems like NFS enables robust (also expensive) mechanisms access files directories. Usually safe set 0 disable heuristic, e.g. working local file system.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeClusterFunctionsTORQUE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ClusterFunctions for OpenPBS/TORQUE Systems — makeClusterFunctionsTORQUE","text":"[ClusterFunctions].","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeExperimentRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"ExperimentRegistry Constructor — makeExperimentRegistry","title":"ExperimentRegistry Constructor — makeExperimentRegistry","text":"makeExperimentRegistry constructs special Registry suitable definition large scale computer experiments. experiments consists Problem Algorithm. can parametrized addExperiments actually define computational jobs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeExperimentRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ExperimentRegistry Constructor — makeExperimentRegistry","text":"","code":"makeExperimentRegistry(   file.dir = \"registry\",   work.dir = getwd(),   conf.file = findConfFile(),   packages = character(0L),   namespaces = character(0L),   source = character(0L),   load = character(0L),   seed = NULL,   make.default = TRUE )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeExperimentRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ExperimentRegistry Constructor — makeExperimentRegistry","text":"file.dir [character(1)]   Path files registry saved.   Default directory “registry” current working directory.   provided path get normalized unless given relative home directory   (.e., starting “~”). Note templates handle relative paths well. pass NA, temporary directory used.   way, can create disposable registries btlapply examples.   default, temporary directory tempdir() used.   want use another directory, e.g. directory shared nodes,   can set configuration file setting variable temp.dir. work.dir [character(1)]   Working directory R process running jobs.   Defaults working directory currently set Registry construction (see getwd).   loadRegistry uses stored work.dir, may also explicitly overwrite ,   e.g., switching another system. provided path get normalized unless given relative home directory   (.e., starting “~”). Note templates handle relative paths well. conf.file [character(1)]   Path configuration file sourced registry created.   configuration file can define batchtools interacts system via ClusterFunctions.   Separating configuration underlying host system R code allows easily move computation another site. file lookup implemented internal (exported) function findConfFile returns first file found following candidates: File “batchtools.conf.R” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. File “batchtools.conf.R” current working directory. File “config.R” user configuration directory reported rappdirs::user_config_dir(\"batchtools\", expand = FALSE) (depending OS, e.g., linux usually resolves “~/.config/batchtools/config.R”). “.batchtools.conf.R” home directory (“~”). “config.R” site config directory reported rappdirs::site_config_dir(\"batchtools\") (depending OS). file can used admins set sane defaults computation site. Set NA want suppress reading configuration file.   configuration file found, gets sourced inside environment registry defaults variables set.   Therefore can set overwrite slots, e.g. default.resources = list(walltime = 3600) set default resources “max.concurrent.jobs”   limit number jobs allowed run simultaneously system. packages [character] Packages always loaded node. Uses require internally. Default character(0). namespaces [character] packages, packages attached. Uses requireNamespace internally. Default character(0). source [character] Files sourced slaves prior executing job. Calls sys.source using .GlobalEnv. load [character] Files loaded slaves prior executing job. Calls load using .GlobalEnv. seed [integer(1)] Start seed jobs. job uses (seed + job.id) seed. Default random integer 1 32768. Note additional seeding mechanism synchronize instantiation Problems ExperimentRegistry. make.default [logical(1)] set TRUE, created registry saved inside package namespace acts default registry. might want switch work multiple registries simultaneously. Default TRUE.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeExperimentRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ExperimentRegistry Constructor — makeExperimentRegistry","text":"[ExperimentRegistry].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeExperimentRegistry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ExperimentRegistry Constructor — makeExperimentRegistry","text":"","code":"tmp = makeExperimentRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive'  # Definde one problem, two algorithms and add them with some parameters: addProblem(reg = tmp, \"p1\",   fun = function(job, data, n, mean, sd, ...) rnorm(n, mean = mean, sd = sd)) #> Adding problem 'p1' addAlgorithm(reg = tmp, \"a1\", fun = function(job, data, instance, ...) mean(instance)) #> Adding algorithm 'a1' addAlgorithm(reg = tmp, \"a2\", fun = function(job, data, instance, ...) median(instance)) #> Adding algorithm 'a2' ids = addExperiments(reg = tmp, list(p1 = data.table::CJ(n = c(50, 100), mean = -2:2, sd = 1:4))) #> Adding 40 experiments ('p1'[40] x 'a1'[1] x repls[1]) ... #> Adding 40 experiments ('p1'[40] x 'a2'[1] x repls[1]) ...  # Overview over defined experiments: tmp$problems #> [1] \"p1\" tmp$algorithms #> [1] \"a1\" \"a2\" summarizeExperiments(reg = tmp) #>    problem algorithm .count #>     <char>    <char>  <int> #> 1:      p1        a1     40 #> 2:      p1        a2     40 summarizeExperiments(reg = tmp, by = c(\"problem\", \"algorithm\", \"n\")) #>    problem algorithm     n .count #>     <char>    <char> <num>  <int> #> 1:      p1        a1    50     20 #> 2:      p1        a1   100     20 #> 3:      p1        a2    50     20 #> 4:      p1        a2   100     20 ids = findExperiments(prob.pars = (n == 50), reg = tmp) print(unwrap(getJobPars(ids, reg = tmp))) #> Key: <job.id> #>     job.id problem algorithm     n  mean    sd #>      <int>  <char>    <char> <num> <int> <int> #>  1:      1      p1        a1    50    -2     1 #>  2:      2      p1        a1    50    -2     2 #>  3:      3      p1        a1    50    -2     3 #>  4:      4      p1        a1    50    -2     4 #>  5:      5      p1        a1    50    -1     1 #>  6:      6      p1        a1    50    -1     2 #>  7:      7      p1        a1    50    -1     3 #>  8:      8      p1        a1    50    -1     4 #>  9:      9      p1        a1    50     0     1 #> 10:     10      p1        a1    50     0     2 #> 11:     11      p1        a1    50     0     3 #> 12:     12      p1        a1    50     0     4 #> 13:     13      p1        a1    50     1     1 #> 14:     14      p1        a1    50     1     2 #> 15:     15      p1        a1    50     1     3 #> 16:     16      p1        a1    50     1     4 #> 17:     17      p1        a1    50     2     1 #> 18:     18      p1        a1    50     2     2 #> 19:     19      p1        a1    50     2     3 #> 20:     20      p1        a1    50     2     4 #> 21:     41      p1        a2    50    -2     1 #> 22:     42      p1        a2    50    -2     2 #> 23:     43      p1        a2    50    -2     3 #> 24:     44      p1        a2    50    -2     4 #> 25:     45      p1        a2    50    -1     1 #> 26:     46      p1        a2    50    -1     2 #> 27:     47      p1        a2    50    -1     3 #> 28:     48      p1        a2    50    -1     4 #> 29:     49      p1        a2    50     0     1 #> 30:     50      p1        a2    50     0     2 #> 31:     51      p1        a2    50     0     3 #> 32:     52      p1        a2    50     0     4 #> 33:     53      p1        a2    50     1     1 #> 34:     54      p1        a2    50     1     2 #> 35:     55      p1        a2    50     1     3 #> 36:     56      p1        a2    50     1     4 #> 37:     57      p1        a2    50     2     1 #> 38:     58      p1        a2    50     2     2 #> 39:     59      p1        a2    50     2     3 #> 40:     60      p1        a2    50     2     4 #>     job.id problem algorithm     n  mean    sd  # Submit jobs submitJobs(reg = tmp) #> Submitting 80 jobs in 80 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE  # Reduce the results of algorithm a1 ids.mean = findExperiments(algo.name = \"a1\", reg = tmp) reduceResults(ids.mean, fun = function(aggr, res, ...) c(aggr, res), reg = tmp) #>  [1] -2.00073766 -1.83988515 -2.19491590 -1.88744748 -1.16661898 -1.01586977 #>  [7] -0.52913619 -0.63585094 -0.09331735  0.11880843  0.22120996  1.22939842 #> [13]  1.00632897  1.26918801  2.11616673  1.81935795  1.90243597  1.93950861 #> [19]  2.33621891  2.81313094 -1.95745534 -2.29431806 -1.82269005 -1.80889629 #> [25] -0.91933173 -1.03820621 -0.95531362 -1.49309041  0.09203207  0.05360571 #> [31]  0.04219920 -0.11534443  1.14488890  0.83504259  0.82821428  1.07835718 #> [37]  2.06274541  2.28296085  2.26426388  1.74159301  # Join info table with all results and calculate mean of results # grouped by n and algorithm ids = findDone(reg = tmp) pars = unwrap(getJobPars(ids, reg = tmp)) results = unwrap(reduceResultsDataTable(ids, fun = function(res) list(res = res), reg = tmp)) tab = ljoin(pars, results) tab[, list(mres = mean(res)), by = c(\"n\", \"algorithm\")] #>        n algorithm        mres #>    <num>    <char>       <num> #> 1:    50        a1 0.270398674 #> 2:   100        a1 0.001062847 #> 3:    50        a2 0.068935673 #> 4:   100        a2 0.020262158"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Registry Constructor — makeRegistry","title":"Registry Constructor — makeRegistry","text":"makeRegistry constructs inter-communication object functions batchtools. communication transactions processed via file system: information required run job stored JobCollection file subdirectory file.dir directory. jobs stores results well computational status information (start time, end time, error message, ...) also file system regular merged parsed master using syncRegistry. integrating new information Registry, Registry serialized file system via saveRegistry. syncRegistry saveRegistry called whenever required internally. Therefore safe quit R session time. Work can later resumed calling loadRegistry de-serializes registry file system. registry created last saved package namespace (unless make.default set FALSE) can retrieved via getDefaultRegistry. Canceled jobs jobs submitted multiple times may leave stray files behind. can swept using sweepRegistry. clearRegistry completely erases jobs registry, including log files results, thus allows start .","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Registry Constructor — makeRegistry","text":"","code":"makeRegistry(   file.dir = \"registry\",   work.dir = getwd(),   conf.file = findConfFile(),   packages = character(0L),   namespaces = character(0L),   source = character(0L),   load = character(0L),   seed = NULL,   make.default = TRUE )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Registry Constructor — makeRegistry","text":"file.dir [character(1)]   Path files registry saved.   Default directory “registry” current working directory.   provided path get normalized unless given relative home directory   (.e., starting “~”). Note templates handle relative paths well. pass NA, temporary directory used.   way, can create disposable registries btlapply examples.   default, temporary directory tempdir() used.   want use another directory, e.g. directory shared nodes,   can set configuration file setting variable temp.dir. work.dir [character(1)]   Working directory R process running jobs.   Defaults working directory currently set Registry construction (see getwd).   loadRegistry uses stored work.dir, may also explicitly overwrite ,   e.g., switching another system. provided path get normalized unless given relative home directory   (.e., starting “~”). Note templates handle relative paths well. conf.file [character(1)]   Path configuration file sourced registry created.   configuration file can define batchtools interacts system via ClusterFunctions.   Separating configuration underlying host system R code allows easily move computation another site. file lookup implemented internal (exported) function findConfFile returns first file found following candidates: File “batchtools.conf.R” path specified environment variable “R_BATCHTOOLS_SEARCH_PATH”. File “batchtools.conf.R” current working directory. File “config.R” user configuration directory reported rappdirs::user_config_dir(\"batchtools\", expand = FALSE) (depending OS, e.g., linux usually resolves “~/.config/batchtools/config.R”). “.batchtools.conf.R” home directory (“~”). “config.R” site config directory reported rappdirs::site_config_dir(\"batchtools\") (depending OS). file can used admins set sane defaults computation site. Set NA want suppress reading configuration file.   configuration file found, gets sourced inside environment registry defaults variables set.   Therefore can set overwrite slots, e.g. default.resources = list(walltime = 3600) set default resources “max.concurrent.jobs”   limit number jobs allowed run simultaneously system. packages [character] Packages always loaded node. Uses require internally. Default character(0). namespaces [character] packages, packages attached. Uses requireNamespace internally. Default character(0). source [character] Files sourced slaves prior executing job. Calls sys.source using .GlobalEnv. load [character] Files loaded slaves prior executing job. Calls load using .GlobalEnv. seed [integer(1)] Start seed jobs. job uses (seed + job.id) seed. Default random integer 1 32768. Note additional seeding mechanism synchronize instantiation Problems ExperimentRegistry. make.default [logical(1)] set TRUE, created registry saved inside package namespace acts default registry. might want switch work multiple registries simultaneously. Default TRUE.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Registry Constructor — makeRegistry","text":"[environment] class “Registry” following slots: file.dir [path]: File directory. work.dir [path]: Working directory. temp.dir [path]: Temporary directory. Used file.dir NA create temporary registries. packages [character()]: Packages load slaves. namespaces [character()]: Namespaces load slaves. seed [integer(1)]: Registry seed. job executed, seed seed + job.id set. cluster.functions [cluster.functions]: Usually set conf.file. Set via call makeClusterFunctions. See example. default.resources [named list()]: Usually set conf.file. Named list default resources. max.concurrent.jobs [integer(1)]: Usually set conf.file. Maximum number concurrent jobs single user current registry system.       submitJobs try respect setting. resource “max.concurrent.jobs” higher precedence. defs [data.table]: Table job definitions (.e. parameters). status [data.table]: Table holding information computational status. Also see getJobStatus. resources [data.table]: Table holding information computational resources used job. Also see getJobResources. tags [data.table]: Table holding information tags. See Tags. hash [character(1)]: Unique hash changes time registry gets saved file system. Can utilized invalidate cache knitr.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeRegistry.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Registry Constructor — makeRegistry","text":"Currently batchtools understands following options set via configuration file: cluster.functions: returned constructor, e.g. makeClusterFunctionsSlurm. default.resources: List resources use. overruled resources specified via submitJobs. temp.dir: Path directory use temporary registries. sleep: Custom sleep function. See waitForJobs. expire.: Number iterations treating jobs expired waitForJobs. compress: Compression algorithm use via saveRDS.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/makeRegistry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Registry Constructor — makeRegistry","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' print(tmp) #> Job Registry #>   Backend  : Interactive #>   File dir : /tmp/batchtools-example/reg #>   Work dir : /home/runner/work/batchtools/batchtools/docs/dev/reference #>   Jobs     : 0 #>   Seed     : 5075 #>   Writeable: TRUE  # Set cluster functions to interactive mode and start jobs in external R sessions tmp$cluster.functions = makeClusterFunctionsInteractive(external = TRUE)  # Change packages to load tmp$packages = c(\"MASS\") saveRegistry(reg = tmp) #> [1] TRUE"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeSubmitJobResult.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a SubmitJobResult — makeSubmitJobResult","title":"Create a SubmitJobResult — makeSubmitJobResult","text":"function intended use cluster functions implementation. Use function implementation makeClusterFunctions create return value submitJob function.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeSubmitJobResult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a SubmitJobResult — makeSubmitJobResult","text":"","code":"makeSubmitJobResult(   status,   batch.id,   log.file = NA_character_,   msg = NA_character_ )"},{"path":"https://batchtools.mlr-org.com/dev/reference/makeSubmitJobResult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a SubmitJobResult — makeSubmitJobResult","text":"status [integer(1)] Launch status job. 0 means success, codes 1 100 temporary errors error greater 100 permanent failure. batch.id [character()] Unique id job batch system, given batch system. Must globally unique job can terminated using just information. array jobs, may vector length equal number jobs array. log.file [character()] Log file. NA, defaults [job.hash].log. cluster functions set array jobs. msg [character(1)] Optional error message case status equal 0. Default “OK”, “TEMPERROR”, “ERROR”, depending status.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/makeSubmitJobResult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a SubmitJobResult — makeSubmitJobResult","text":"[SubmitJobResult]. list, containing   status, batch.id msg.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResults.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce Results — reduceResults","title":"Reduce Results — reduceResults","text":"version Reduce Registry objects iterates finished jobs aggregates . jobs must terminated, error raised otherwise.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce Results — reduceResults","text":"","code":"reduceResults(fun, ids = NULL, init, ..., reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce Results — reduceResults","text":"fun [function] function reduce results. result previous iterations (init) passed first argument, result -th iteration second. See Reduce examples. function formal argument “job”, Job/Experiment also passed function (named). ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findDone. Invalid ids ignored. init [] Initial element, used Reduce. missing, reduction uses result first job init reduction starts second job. ... [] Additional arguments passed function fun. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce Results — reduceResults","text":"Aggregated results order provided ids.   Return type depends user function. ids   empty, reduceResults returns init (available) NULL otherwise.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResults.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reduce Results — reduceResults","text":"thousands jobs, disabling progress bar (options(batchtools.progress = FALSE)) can significantly increase performance.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResults.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce Results — reduceResults","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(function(a, b) list(sum = a+b, prod = a*b), a = 1:3, b = 1:3, reg = tmp) #> Adding 3 jobs ... submitJobs(reg = tmp) #> Submitting 3 jobs in 3 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE  # Extract element sum from each result reduceResults(function(aggr, res) c(aggr, res$sum), init = list(), reg = tmp) #> [[1]] #> [1] 2 #>  #> [[2]] #> [1] 4 #>  #> [[3]] #> [1] 6 #>   # Aggregate element sum via '+' reduceResults(function(aggr, res) aggr + res$sum, init = 0, reg = tmp) #> [1] 12  # Aggregate element prod via '*' where parameter b < 3 reduce = function(aggr, res, job) {   if (job$pars$b >= 3)     return(aggr)   aggr * res$prod } reduceResults(reduce, init = 1, reg = tmp) #> [1] 4  # Reduce to data.frame() (inefficient, use reduceResultsDataTable() instead) reduceResults(rbind, init = data.frame(), reg = tmp) #>   sum prod #> 1   2    1 #> 2   4    4 #> 3   6    9  # Reduce to data.frame by collecting results first, then utilize vectorization of rbind: res = reduceResultsList(fun = as.data.frame, reg = tmp) do.call(rbind, res) #>   sum prod #> 1   2    1 #> 2   4    4 #> 3   6    9  # Reduce with custom combine function: comb = function(x, y) list(sum = x$sum + y$sum, prod = x$prod * y$prod) reduceResults(comb, reg = tmp) #> $sum #> [1] 12 #>  #> $prod #> [1] 36 #>   # The same with neutral element NULL comb = function(x, y) if (is.null(x)) y else list(sum = x$sum + y$sum, prod = x$prod * y$prod) reduceResults(comb, init = NULL, reg = tmp) #> $sum #> [1] 12 #>  #> $prod #> [1] 36 #>   # Alternative: Reduce in list, reduce manually in a 2nd step res = reduceResultsList(reg = tmp) Reduce(comb, res) #> $sum #> [1] 12 #>  #> $prod #> [1] 36 #>"},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResultsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Functions on Results — reduceResultsList","title":"Apply Functions on Results — reduceResultsList","text":"Applies function results finished jobs thereby collects list data.table. later requires provided function return list (data.frame) scalar values. See rbindlist features limitations aggregation. jobs terminated, respective result NULL.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResultsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Functions on Results — reduceResultsList","text":"","code":"reduceResultsList(   ids = NULL,   fun = NULL,   ...,   missing.val,   reg = getDefaultRegistry() )  reduceResultsDataTable(   ids = NULL,   fun = NULL,   ...,   missing.val,   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResultsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Functions on Results — reduceResultsList","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findDone. Invalid ids ignored. fun [function] Function apply result. result passed unnamed first argument. NULL, identity used. function formal argument “job”, Job/Experiment also passed function. ... [] Additional arguments passed function fun. missing.val [] Value impute result job finished. provided result missing, exception raised. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResultsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Functions on Results — reduceResultsList","text":"reduceResultsList returns list results order provided ids.   reduceResultsDataTable returns data.table columns “job.id” additional result columns   created via rbindlist, sorted “job.id”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResultsList.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Apply Functions on Results — reduceResultsList","text":"thousands jobs, disabling progress bar (options(batchtools.progress = FALSE)) can significantly increase performance.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/reduceResultsList.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Functions on Results — reduceResultsList","text":"","code":"### Example 1 - reduceResultsList tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg1' using cluster functions 'Interactive' batchMap(function(x) x^2, x = 1:10, reg = tmp) #> Adding 10 jobs ... submitJobs(reg = tmp) #> Submitting 10 jobs in 10 chunks using cluster functions 'Interactive' ... waitForJobs(reg = tmp) #> [1] TRUE reduceResultsList(fun = sqrt, reg = tmp) #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 2 #>  #> [[3]] #> [1] 3 #>  #> [[4]] #> [1] 4 #>  #> [[5]] #> [1] 5 #>  #> [[6]] #> [1] 6 #>  #> [[7]] #> [1] 7 #>  #> [[8]] #> [1] 8 #>  #> [[9]] #> [1] 9 #>  #> [[10]] #> [1] 10 #>   ### Example 2 - reduceResultsDataTable tmp = makeExperimentRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg2' using cluster functions 'Interactive'  # add first problem fun = function(job, data, n, mean, sd, ...) rnorm(n, mean = mean, sd = sd) addProblem(\"rnorm\", fun = fun, reg = tmp) #> Adding problem 'rnorm'  # add second problem fun = function(job, data, n, lambda, ...) rexp(n, rate = lambda) addProblem(\"rexp\", fun = fun, reg = tmp) #> Adding problem 'rexp'  # add first algorithm fun = function(instance, method, ...) if (method == \"mean\") mean(instance) else median(instance) addAlgorithm(\"average\", fun = fun, reg = tmp) #> Adding algorithm 'average'  # add second algorithm fun = function(instance, ...) sd(instance) addAlgorithm(\"deviation\", fun = fun, reg = tmp) #> Adding algorithm 'deviation'  # define problem and algorithm designs library(data.table) prob.designs = algo.designs = list() prob.designs$rnorm = CJ(n = 100, mean = -1:1, sd = 1:5) prob.designs$rexp = data.table(n = 100, lambda = 1:5) algo.designs$average = data.table(method = c(\"mean\", \"median\")) algo.designs$deviation = data.table()  # add experiments and submit addExperiments(prob.designs, algo.designs, reg = tmp) #> Adding 30 experiments ('rnorm'[15] x 'average'[2] x repls[1]) ... #> Adding 15 experiments ('rnorm'[15] x 'deviation'[1] x repls[1]) ... #> Adding 10 experiments ('rexp'[5] x 'average'[2] x repls[1]) ... #> Adding 5 experiments ('rexp'[5] x 'deviation'[1] x repls[1]) ... submitJobs(reg = tmp) #> Submitting 60 jobs in 60 chunks using cluster functions 'Interactive' ...  # collect results and join them with problem and algorithm paramters res = ijoin(   getJobPars(reg = tmp),   reduceResultsDataTable(reg = tmp, fun = function(x) list(res = x)) ) unwrap(res, sep = \".\") #> Key: <job.id> #>     job.id problem algorithm prob.pars.n prob.pars.mean prob.pars.sd #>      <int>  <char>    <char>       <num>          <int>        <int> #>  1:      1   rnorm   average         100             -1            1 #>  2:      2   rnorm   average         100             -1            1 #>  3:      3   rnorm   average         100             -1            2 #>  4:      4   rnorm   average         100             -1            2 #>  5:      5   rnorm   average         100             -1            3 #>  6:      6   rnorm   average         100             -1            3 #>  7:      7   rnorm   average         100             -1            4 #>  8:      8   rnorm   average         100             -1            4 #>  9:      9   rnorm   average         100             -1            5 #> 10:     10   rnorm   average         100             -1            5 #> 11:     11   rnorm   average         100              0            1 #> 12:     12   rnorm   average         100              0            1 #> 13:     13   rnorm   average         100              0            2 #> 14:     14   rnorm   average         100              0            2 #> 15:     15   rnorm   average         100              0            3 #> 16:     16   rnorm   average         100              0            3 #> 17:     17   rnorm   average         100              0            4 #> 18:     18   rnorm   average         100              0            4 #> 19:     19   rnorm   average         100              0            5 #> 20:     20   rnorm   average         100              0            5 #> 21:     21   rnorm   average         100              1            1 #> 22:     22   rnorm   average         100              1            1 #> 23:     23   rnorm   average         100              1            2 #> 24:     24   rnorm   average         100              1            2 #> 25:     25   rnorm   average         100              1            3 #> 26:     26   rnorm   average         100              1            3 #> 27:     27   rnorm   average         100              1            4 #> 28:     28   rnorm   average         100              1            4 #> 29:     29   rnorm   average         100              1            5 #> 30:     30   rnorm   average         100              1            5 #> 31:     31   rnorm deviation         100             -1            1 #> 32:     32   rnorm deviation         100             -1            2 #> 33:     33   rnorm deviation         100             -1            3 #> 34:     34   rnorm deviation         100             -1            4 #> 35:     35   rnorm deviation         100             -1            5 #> 36:     36   rnorm deviation         100              0            1 #> 37:     37   rnorm deviation         100              0            2 #> 38:     38   rnorm deviation         100              0            3 #> 39:     39   rnorm deviation         100              0            4 #> 40:     40   rnorm deviation         100              0            5 #> 41:     41   rnorm deviation         100              1            1 #> 42:     42   rnorm deviation         100              1            2 #> 43:     43   rnorm deviation         100              1            3 #> 44:     44   rnorm deviation         100              1            4 #> 45:     45   rnorm deviation         100              1            5 #> 46:     46    rexp   average         100             NA           NA #> 47:     47    rexp   average         100             NA           NA #> 48:     48    rexp   average         100             NA           NA #> 49:     49    rexp   average         100             NA           NA #> 50:     50    rexp   average         100             NA           NA #> 51:     51    rexp   average         100             NA           NA #> 52:     52    rexp   average         100             NA           NA #> 53:     53    rexp   average         100             NA           NA #> 54:     54    rexp   average         100             NA           NA #> 55:     55    rexp   average         100             NA           NA #> 56:     56    rexp deviation         100             NA           NA #> 57:     57    rexp deviation         100             NA           NA #> 58:     58    rexp deviation         100             NA           NA #> 59:     59    rexp deviation         100             NA           NA #> 60:     60    rexp deviation         100             NA           NA #>     job.id problem algorithm prob.pars.n prob.pars.mean prob.pars.sd #>     prob.pars.lambda algo.pars.method   result.res #>                <int>           <char>        <num> #>  1:               NA             mean -1.092018851 #>  2:               NA           median -0.863780644 #>  3:               NA             mean -1.084890423 #>  4:               NA           median -1.505171392 #>  5:               NA             mean -1.381319138 #>  6:               NA           median -1.341051423 #>  7:               NA             mean -1.188083630 #>  8:               NA           median  0.029939562 #>  9:               NA             mean -0.987419910 #> 10:               NA           median -1.673002281 #> 11:               NA             mean  0.007267359 #> 12:               NA           median  0.127401909 #> 13:               NA             mean -0.179617350 #> 14:               NA           median  0.046125736 #> 15:               NA             mean -0.057929853 #> 16:               NA           median  0.140366680 #> 17:               NA             mean -0.388849478 #> 18:               NA           median -1.207701427 #> 19:               NA             mean  0.042334184 #> 20:               NA           median -0.381653696 #> 21:               NA             mean  0.907293957 #> 22:               NA           median  1.033215601 #> 23:               NA             mean  1.020619322 #> 24:               NA           median  0.876104940 #> 25:               NA             mean  0.679306393 #> 26:               NA           median  0.977987955 #> 27:               NA             mean  0.675594915 #> 28:               NA           median  1.366615131 #> 29:               NA             mean  1.189950292 #> 30:               NA           median  0.263092706 #> 31:               NA             <NA>  1.040412625 #> 32:               NA             <NA>  2.392300899 #> 33:               NA             <NA>  3.042692900 #> 34:               NA             <NA>  4.263774294 #> 35:               NA             <NA>  5.296092785 #> 36:               NA             <NA>  1.071510659 #> 37:               NA             <NA>  2.072637870 #> 38:               NA             <NA>  3.153765268 #> 39:               NA             <NA>  3.419489935 #> 40:               NA             <NA>  5.558785921 #> 41:               NA             <NA>  1.012589238 #> 42:               NA             <NA>  2.015986064 #> 43:               NA             <NA>  3.170339048 #> 44:               NA             <NA>  4.281061044 #> 45:               NA             <NA>  4.988645174 #> 46:                1             mean  0.945622941 #> 47:                1           median  0.619859008 #> 48:                2             mean  0.446385905 #> 49:                2           median  0.420682183 #> 50:                3             mean  0.397613162 #> 51:                3           median  0.306781776 #> 52:                4             mean  0.277069910 #> 53:                4           median  0.165324176 #> 54:                5             mean  0.182106656 #> 55:                5           median  0.144752066 #> 56:                1             <NA>  0.942306695 #> 57:                2             <NA>  0.453601669 #> 58:                3             <NA>  0.292487926 #> 59:                4             <NA>  0.210416655 #> 60:                5             <NA>  0.189556888 #>     prob.pars.lambda algo.pars.method   result.res"},{"path":"https://batchtools.mlr-org.com/dev/reference/removeExperiments.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove Experiments — removeExperiments","title":"Remove Experiments — removeExperiments","text":"Remove Experiments ExperimentRegistry. function automatically checks jobs reset either pending running. However, implemented heuristic fails, can lead inconsistencies data base. Use care jobs running.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/removeExperiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove Experiments — removeExperiments","text":"","code":"removeExperiments(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/removeExperiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove Experiments — removeExperiments","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults job. Invalid ids ignored. reg [ExperimentRegistry] Registry. explicitly passed, uses last created registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/removeExperiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove Experiments — removeExperiments","text":"[data.table] removed job ids, invisibly.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/removeRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a Registry from the File System — removeRegistry","title":"Remove a Registry from the File System — removeRegistry","text":"files erased file system, including results. wish remove intermediate files, use sweepRegistry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/removeRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a Registry from the File System — removeRegistry","text":"","code":"removeRegistry(wait = 5, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/removeRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a Registry from the File System — removeRegistry","text":"wait [numeric(1)] Seconds wait proceeding. safety measure accidentally remove precious files. Set 0 non-interactive scripts disable precaution. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/removeRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove a Registry from the File System — removeRegistry","text":"[character(1)]: Path deleted file directory.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/removeRegistry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove a Registry from the File System — removeRegistry","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' removeRegistry(0, tmp) #> Recursively removing files in '/tmp/batchtools-example/reg' ..."},{"path":"https://batchtools.mlr-org.com/dev/reference/resetJobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset the Computational State of Jobs — resetJobs","title":"Reset the Computational State of Jobs — resetJobs","text":"Resets computational state jobs Registry. function automatically checks jobs reset either pending running. However, implemented heuristic fails, can lead inconsistencies data base. Use care jobs running.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/resetJobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset the Computational State of Jobs — resetJobs","text":"","code":"resetJobs(ids = NULL, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/resetJobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset the Computational State of Jobs — resetJobs","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults job. Invalid ids ignored. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/resetJobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reset the Computational State of Jobs — resetJobs","text":"[data.table] job ids reset.   See JoinTables examples working job tables.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/runHook.html","id":null,"dir":"Reference","previous_headings":"","what":"Trigger Evaluation of Custom Function — runHook","title":"Trigger Evaluation of Custom Function — runHook","text":"Hooks allow trigger functions calls specific events. can specified via ClusterFunctions triggered following events: pre.sync function(reg, fns, ...): Run synchronizing registry master. fn character vector paths update files. post.sync function(reg, updates, ...): Run synchronizing registry master. updates data.table processed updates. pre.submit.job function(reg, ...): Run job successfully submitted scheduler master. post.submit.job function(reg, ...): Run job successfully submitted scheduler master. pre.submit function(reg, ...): Run job submitted scheduler. post.submit function(reg, ...): Run jobs submitted schedule. pre..collection function(reg, reader, ...): Run starting job collection slave.     reader internal cache object. post..collection function(reg, updates, reader, ...): Run jobs chunk terminated slave.     updates data.table updates merged Registry master.     reader internal cache object. pre.kill function(reg, ids, ...): Run job killed. post.kill function(reg, ids, ...): Run jobs killed. ids return value killJobs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/runHook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trigger Evaluation of Custom Function — runHook","text":"","code":"runHook(obj, hook, ...)"},{"path":"https://batchtools.mlr-org.com/dev/reference/runHook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trigger Evaluation of Custom Function — runHook","text":"obj [Registry | JobCollection] Registry contains ClusterFunctions element “hooks” JobCollection holds subset functions executed remotely. hook [character(1)] ID hook string. ... [] Additional arguments passed function referenced hook. See description.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/runHook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trigger Evaluation of Custom Function — runHook","text":"Return value called function, NULL hook  specified ID.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/runOSCommand.html","id":null,"dir":"Reference","previous_headings":"","what":"Run OS Commands on Local or Remote Machines — runOSCommand","title":"Run OS Commands on Local or Remote Machines — runOSCommand","text":"helper function run arbitrary OS commands local remote machines. interface similar system2, always returns exit status output.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/runOSCommand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run OS Commands on Local or Remote Machines — runOSCommand","text":"","code":"runOSCommand(   sys.cmd,   sys.args = character(0L),   stdin = \"\",   nodename = \"localhost\" )"},{"path":"https://batchtools.mlr-org.com/dev/reference/runOSCommand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run OS Commands on Local or Remote Machines — runOSCommand","text":"sys.cmd [character(1)] Command run. sys.args [character] Arguments sys.cmd. stdin [character(1)] Argument passed system2. nodename [character(1)] Name SSH node run command . set “localhost” (default), command piped SSH.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/runOSCommand.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run OS Commands on Local or Remote Machines — runOSCommand","text":"[named list] “sys.cmd”, “sys.args”, “exit.code” (integer), “output” (character).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/runOSCommand.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run OS Commands on Local or Remote Machines — runOSCommand","text":"","code":"if (FALSE) { # \\dontrun{ runOSCommand(\"ls\") runOSCommand(\"ls\", \"-al\") runOSCommand(\"notfound\") } # }"},{"path":"https://batchtools.mlr-org.com/dev/reference/saveRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Store the Registy to the File System — saveRegistry","title":"Store the Registy to the File System — saveRegistry","text":"Stores registry file system “file.dir” (specified construction makeRegistry, can accessed via reg$file.dir). function usually called internally whenever needed.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/saveRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Store the Registy to the File System — saveRegistry","text":"","code":"saveRegistry(reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/saveRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Store the Registy to the File System — saveRegistry","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/saveRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Store the Registy to the File System — saveRegistry","text":"[logical(1)]: TRUE registry saved,   FALSE otherwise (registry read-).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/showLog.html","id":null,"dir":"Reference","previous_headings":"","what":"Inspect Log Files — showLog","title":"Inspect Log Files — showLog","text":"showLog opens log pager. customization, see file.show. getLog returns log character vector.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/showLog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inspect Log Files — showLog","text":"","code":"showLog(id, reg = getDefaultRegistry())  getLog(id, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/showLog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inspect Log Files — showLog","text":"id [integer(1) data.table] Single integer specify job data.table column job.id exactly one row. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/showLog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inspect Log Files — showLog","text":"Nothing.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/showLog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inspect Log Files — showLog","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive'  # Create some dummy jobs fun = function(i) {   if (i == 3) stop(i)   if (i %% 2 == 1) warning(\"That's odd.\") } ids = batchMap(fun, i = 1:5, reg = tmp) #> Adding 5 jobs ... submitJobs(reg = tmp) #> Submitting 5 jobs in 5 chunks using cluster functions 'Interactive' ... #> Warning: That's odd. #> Error in (function (i)  : 3 #> Warning: That's odd. waitForJobs(reg = tmp) #> [1] FALSE getStatus(reg = tmp) #> Status for 5 jobs at 2025-05-22 14:40:04: #>   Submitted    : 5 (100.0%) #>   -- Queued    : 0 (  0.0%) #>   -- Started   : 5 (100.0%) #>   ---- Running : 0 (  0.0%) #>   ---- Done    : 4 ( 80.0%) #>   ---- Error   : 1 ( 20.0%) #>   ---- Expired : 0 (  0.0%)  writeLines(getLog(ids[1], reg = tmp)) #> ### [bt]: This is batchtools v0.9.17.9000 #> ### [bt]: Starting calculation of 1 jobs #> ### [bt]: Setting working directory to '/home/runner/work/batchtools/batchtools/docs/dev/reference' #> ### [bt]: Memory measurement disabled #> ### [bt]: Starting job [batchtools job.id=1] #> ### [bt]: Setting seed to 5192 ... #>  #> ### [bt]: Job terminated successfully [batchtools job.id=1] #> ### [bt]: Calculation finished! if (FALSE) { # \\dontrun{ showLog(ids[1], reg = tmp) } # }  grepLogs(pattern = \"warning\", ignore.case = TRUE, reg = tmp) #> Key: <job.id> #> Empty data.table (0 rows and 2 cols): job.id,matches"},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Submit Jobs to the Batch Systems — submitJobs","title":"Submit Jobs to the Batch Systems — submitJobs","text":"Submits defined jobs batch system. submitting jobs, can use waitForJobs wait termination jobs call reduceResultsList/reduceResults collect partial results. progress can monitored getStatus.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submit Jobs to the Batch Systems — submitJobs","text":"","code":"submitJobs(   ids = NULL,   resources = list(),   sleep = NULL,   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submit Jobs to the Batch Systems — submitJobs","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findNotSubmitted. Invalid ids ignored. resources [named list] Computational  resources jobs submit. actual elements list (e.g. something like “walltime” “nodes”) depend template file, exceptions outlined section 'Resources'. Default settings system can set configuration file defining named list default.resources. Note settings merged name, e.g. merging list(walltime = 300) list(walltime = 400, memory = 512) result list(walltime = 300, memory = 512). holds individual job resources passed additional column ids (c.f. section 'Resources'). sleep [function() | numeric(1)] Parameter control duration sleep temporary errors. can pass absolute numeric value seconds function() returns number seconds sleep -th iteration temporary errors. provided (NULL), tries read value (number/function) configuration file (stored reg$sleep) defaults function exponential backoff 5 120 seconds. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Submit Jobs to the Batch Systems — submitJobs","text":"[data.table] columns “job.id” “chunk”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Submit Jobs to the Batch Systems — submitJobs","text":"large number jobs, disabling progress bar (options(batchtools.progress = FALSE)) can significantly increase performance submitJobs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"resources","dir":"Reference","previous_headings":"","what":"Resources","title":"Submit Jobs to the Batch Systems — submitJobs","text":"can pass arbitrary resources submitJobs() available cluster function template. resources' names standardized good practice stick following nomenclature avoid confusion: walltime: Upper time limit seconds jobs get killed scheduler. Can passed additional column part ids set per-job resources. memory: Memory limit Mb. jobs exceed limit, usually killed scheduler. Can passed additional column part ids set per-job resources. ncpus: Number (physical) CPUs use slave. Can passed additional column part ids set per-job resources. omp.threads: Number threads use via OpenMP. Used set environment variable “OMP_NUM_THREADS”. Can passed additional column part ids set per-job resources. pp.size: Maximum size pointer protection stack, see Memory. blas.threads: Number threads use BLAS backend. Used set environment variables “MKL_NUM_THREADS” “OPENBLAS_NUM_THREADS”. Can passed additional column part ids set per-job resources. measure.memory: Enable memory measurement jobs. Comes small runtime overhead. chunks..arrayjobs: Execute chunks array jobs. pm.backend: Start parallelMap backend slave. foreach.backend: Start foreach backend slave. clusters: Resource used Slurm select set clusters run sbatch/squeue/scancel .","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"chunking-of-jobs","dir":"Reference","previous_headings":"","what":"Chunking of Jobs","title":"Submit Jobs to the Batch Systems — submitJobs","text":"Multiple jobs can grouped (chunked) together executed sequentially batch system single batch job. especially useful avoid overburding scheduler submitting thousands jobs simultaneously. chunk jobs together, job ids must provided data.frame columns “job.id” “chunk” (integer). jobs chunk number executed sequentially inside batch job. utility functions chunk, binpack lpt can assist grouping jobs.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"array-jobs","dir":"Reference","previous_headings":"","what":"Array Jobs","title":"Submit Jobs to the Batch Systems — submitJobs","text":"cluster supports array jobs, can set resource chunks..arrayjobs TRUE order execute chunks job arrays cluster. chunk size n, batchtools creates JobCollection (possibly heterogeneous) jobs submitted scheduler single array job n repetitions. repetition, JobCollection first read file system, subsetted -th job using environment variable reg$cluster.functions$array.var (depending cluster backend, defined automatically) finally executed.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"order-of-submission","dir":"Reference","previous_headings":"","what":"Order of Submission","title":"Submit Jobs to the Batch Systems — submitJobs","text":"Jobs submitted order chunks, .e. jobs chunk number sort(unique(ids$chunk))[1] first, jobs chunk number sort(unique(ids$chunk))[2] . chunks provided, jobs submitted order ids$job.id.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"limiting-the-number-of-jobs","dir":"Reference","previous_headings":"","what":"Limiting the Number of Jobs","title":"Submit Jobs to the Batch Systems — submitJobs","text":"requested, submitJobs tries limit number concurrent jobs user waiting jobs terminate submitting new ones. can controlled setting “max.concurrent.jobs” configuration file (see Registry) setting resource “max.concurrent.jobs” maximum number jobs run simultaneously. set, setting via resource takes precedence setting configuration.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"measuring-memory","dir":"Reference","previous_headings":"","what":"Measuring Memory","title":"Submit Jobs to the Batch Systems — submitJobs","text":"Setting resource measure.memory TRUE turns memory measurement: gc called  directly job difference stored internal database. Note just rough estimate neither work reliably external code like C/C++ combination threading.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"inner-parallelization","dir":"Reference","previous_headings":"","what":"Inner Parallelization","title":"Submit Jobs to the Batch Systems — submitJobs","text":"Inner parallelization typically done via threading, sockets MPI. Two backends supported assist setting inner parallelization. first package parallelMap. set resource “pm.backend” “multicore”, “socket” “mpi”, parallelStart called slave first job chunk started parallelStop called last job terminated. way, resources inner parallelization can set get automatically stored just like computational resources. function provided user just call parallelMap start parallelization using preconfigured backend. control number CPUs, set resource ncpus. Otherwise ncpus defaults number available CPUs (reported (see detectCores)) executing machine multicore socket mode defaults return value mpi.universe.size-1 MPI. template must set handle parallelization, e.g. request right number CPUs start R mpirun. may pass options like level parallelStart via named list “pm.opts”. second supported parallelization backend foreach. set resource “foreach.backend” “seq” (sequential mode), “parallel” (doParallel) “mpi” (doMPI), requested foreach backend automatically registered slave. , resource ncpus used determine number CPUs. Neither namespace parallelMap namespace foreach attached. manually via library let registry load packages .","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/submitJobs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Submit Jobs to the Batch Systems — submitJobs","text":"","code":"### Example 1: Submit subsets of jobs tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg1' using cluster functions 'Interactive'  # toy function which fails if x is even and an input file does not exists fun = function(x, fn) if (x %% 2 == 0 && !file.exists(fn)) stop(\"file not found\") else x  # define jobs via batchMap fn = tempfile() ids = batchMap(fun, 1:20, reg = tmp, fn = fn) #> Adding 20 jobs ...  # submit some jobs ids = 1:10 submitJobs(ids, reg = tmp) #> Submitting 10 jobs in 10 chunks using cluster functions 'Interactive' ... #> Error in (function (x, fn)  : file not found #> Error in (function (x, fn)  : file not found #> Error in (function (x, fn)  : file not found #> Error in (function (x, fn)  : file not found #> Error in (function (x, fn)  : file not found waitForJobs(ids, reg = tmp) #> [1] FALSE getStatus(reg = tmp) #> Status for 20 jobs at 2025-05-22 14:40:05: #>   Submitted    : 10 ( 50.0%) #>   -- Queued    :  0 (  0.0%) #>   -- Started   : 10 ( 50.0%) #>   ---- Running :  0 (  0.0%) #>   ---- Done    :  5 ( 25.0%) #>   ---- Error   :  5 ( 25.0%) #>   ---- Expired :  0 (  0.0%)  # create the required file and re-submit failed jobs file.create(fn) #> [1] TRUE submitJobs(findErrors(ids, reg = tmp), reg = tmp) #> Submitting 5 jobs in 5 chunks using cluster functions 'Interactive' ... getStatus(reg = tmp) #> Status for 20 jobs at 2025-05-22 14:40:05: #>   Submitted    : 10 ( 50.0%) #>   -- Queued    :  0 (  0.0%) #>   -- Started   : 10 ( 50.0%) #>   ---- Running :  0 (  0.0%) #>   ---- Done    : 10 ( 50.0%) #>   ---- Error   :  0 (  0.0%) #>   ---- Expired :  0 (  0.0%)  # submit remaining jobs which have not yet been submitted ids = findNotSubmitted(reg = tmp) submitJobs(ids, reg = tmp) #> Submitting 10 jobs in 10 chunks using cluster functions 'Interactive' ... getStatus(reg = tmp) #> Status for 20 jobs at 2025-05-22 14:40:06: #>   Submitted    : 20 (100.0%) #>   -- Queued    :  0 (  0.0%) #>   -- Started   : 20 (100.0%) #>   ---- Running :  0 (  0.0%) #>   ---- Done    : 20 (100.0%) #>   ---- Error   :  0 (  0.0%) #>   ---- Expired :  0 (  0.0%)  # collect results reduceResultsList(reg = tmp) #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 2 #>  #> [[3]] #> [1] 3 #>  #> [[4]] #> [1] 4 #>  #> [[5]] #> [1] 5 #>  #> [[6]] #> [1] 6 #>  #> [[7]] #> [1] 7 #>  #> [[8]] #> [1] 8 #>  #> [[9]] #> [1] 9 #>  #> [[10]] #> [1] 10 #>  #> [[11]] #> [1] 11 #>  #> [[12]] #> [1] 12 #>  #> [[13]] #> [1] 13 #>  #> [[14]] #> [1] 14 #>  #> [[15]] #> [1] 15 #>  #> [[16]] #> [1] 16 #>  #> [[17]] #> [1] 17 #>  #> [[18]] #> [1] 18 #>  #> [[19]] #> [1] 19 #>  #> [[20]] #> [1] 20 #>   ### Example 2: Using memory measurement tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg2' using cluster functions 'Interactive'  # Toy function which creates a large matrix and returns the column sums fun = function(n, p) colMeans(matrix(runif(n*p), n, p))  # Arguments to fun: args = data.table::CJ(n = c(1e4, 1e5), p = c(10, 50)) # like expand.grid() print(args) #> Key: <n, p> #>        n     p #>    <num> <num> #> 1: 1e+04    10 #> 2: 1e+04    50 #> 3: 1e+05    10 #> 4: 1e+05    50  # Map function to create jobs ids = batchMap(fun, args = args, reg = tmp) #> Adding 4 jobs ...  # Set resources: enable memory measurement res = list(measure.memory = TRUE)  # Submit jobs using the currently configured cluster functions submitJobs(ids, resources = res, reg = tmp) #> Submitting 4 jobs in 4 chunks using cluster functions 'Interactive' ...  # Retrive information about memory, combine with parameters info = ijoin(getJobStatus(reg = tmp)[, .(job.id, mem.used)], getJobPars(reg = tmp)) print(unwrap(info)) #> Key: <job.id> #>    job.id mem.used     n     p #>     <int>    <num> <num> <num> #> 1:      1 163.0077 1e+04    10 #> 2:      2 163.0085 1e+04    50 #> 3:      3 163.0084 1e+05    10 #> 4:      4 163.0087 1e+05    50  # Combine job info with results -> each job is aggregated using mean() unwrap(ijoin(info, reduceResultsDataTable(fun = function(res) list(res = mean(res)), reg = tmp))) #> Key: <job.id> #>    job.id mem.used     n     p       res #>     <int>    <num> <num> <num>     <num> #> 1:      1 163.0077 1e+04    10 0.5005778 #> 2:      2 163.0085 1e+04    50 0.4992527 #> 3:      3 163.0084 1e+05    10 0.5000026 #> 4:      4 163.0087 1e+05    50 0.4999301  ### Example 3: Multicore execution on the slave tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg3' using cluster functions 'Interactive'  # Function which sleeps 10 seconds, i-times f = function(i) {   parallelMap::parallelMap(Sys.sleep, rep(10, i)) }  # Create one job with parameter i=4 ids = batchMap(f, i = 4, reg = tmp) #> Adding 1 jobs ...  # Set resources: Use parallelMap in multicore mode with 4 CPUs # batchtools internally loads the namespace of parallelMap and then # calls parallelStart() before the job and parallelStop() right # after the job last job in the chunk terminated. res = list(pm.backend = \"multicore\", ncpus = 4)  if (FALSE) { # \\dontrun{ # Submit both jobs and wait for them submitJobs(resources = res, reg = tmp) waitForJobs(reg = tmp)  # If successfull, the running time should be ~10s getJobTable(reg = tmp)[, .(job.id, time.running)]  # There should also be a note in the log: grepLogs(pattern = \"parallelMap\", reg = tmp) } # }"},{"path":"https://batchtools.mlr-org.com/dev/reference/summarizeExperiments.html","id":null,"dir":"Reference","previous_headings":"","what":"Quick Summary over Experiments — summarizeExperiments","title":"Quick Summary over Experiments — summarizeExperiments","text":"Returns frequency table defined experiments. See ExperimentRegistry example.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/summarizeExperiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quick Summary over Experiments — summarizeExperiments","text":"","code":"summarizeExperiments(   ids = NULL,   by = c(\"problem\", \"algorithm\"),   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/summarizeExperiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quick Summary over Experiments — summarizeExperiments","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults jobs. Invalid ids ignored. [character] Split resulting table columns getJobPars. reg [ExperimentRegistry] Registry. explicitly passed, uses last created registry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/summarizeExperiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quick Summary over Experiments — summarizeExperiments","text":"[data.table] frequencies.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/sweepRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Consistency and Remove Obsolete Information — sweepRegistry","title":"Check Consistency and Remove Obsolete Information — sweepRegistry","text":"Canceled jobs jobs submitted multiple times may leave stray files behind. function checks registry consistency removes obsolete files redundant data base entries.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/sweepRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Consistency and Remove Obsolete Information — sweepRegistry","text":"","code":"sweepRegistry(reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/sweepRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Consistency and Remove Obsolete Information — sweepRegistry","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/syncRegistry.html","id":null,"dir":"Reference","previous_headings":"","what":"Synchronize the Registry — syncRegistry","title":"Synchronize the Registry — syncRegistry","text":"Parses update files written slaves file system updates internal data base.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/syncRegistry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synchronize the Registry — syncRegistry","text":"","code":"syncRegistry(reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/syncRegistry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synchronize the Registry — syncRegistry","text":"reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/syncRegistry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synchronize the Registry — syncRegistry","text":"[logical(1)]: TRUE state changed, FALSE otherwise.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/testJob.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Jobs Interactively — testJob","title":"Run Jobs Interactively — testJob","text":"Starts single job local machine.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/testJob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Jobs Interactively — testJob","text":"","code":"testJob(id, external = FALSE, reg = getDefaultRegistry())"},{"path":"https://batchtools.mlr-org.com/dev/reference/testJob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Jobs Interactively — testJob","text":"id [integer(1) data.table] Single integer specify job data.table column job.id exactly one row. external [logical(1)]  Run job external R session? TRUE, starts fresh R  session local machine execute execJob.  able use debug tools like traceback  browser. external set FALSE (default) hand,  testJob execute job current R session usual  debugging tools work. However, spotting missing variable declarations ( possibly resolved global environment) impossible.  holds missing package dependency declarations. reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/testJob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Jobs Interactively — testJob","text":"Returns result job successful.","code":""},{"path":[]},{"path":"https://batchtools.mlr-org.com/dev/reference/testJob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Jobs Interactively — testJob","text":"","code":"tmp = makeRegistry(file.dir = NA, make.default = FALSE) #> No readable configuration file found #> Created registry in '/tmp/batchtools-example/reg' using cluster functions 'Interactive' batchMap(function(x) if (x == 2) xxx else x, 1:2, reg = tmp) #> Adding 2 jobs ... testJob(1, reg = tmp) #> ### [bt]: Setting seed to 11688 ... #> [1] 1 if (FALSE) { # \\dontrun{ testJob(2, reg = tmp) } # }"},{"path":"https://batchtools.mlr-org.com/dev/reference/unwrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Unwrap Nested Data Frames — unwrap","title":"Unwrap Nested Data Frames — unwrap","text":"functions (e.g., getJobPars, getJobResources reduceResultsDataTable return data.table columns type list. columns can unnested/unwrapped function. contents columns  transformed data.table cbind-ed input data.frame x, replacing original nested column.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/unwrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unwrap Nested Data Frames — unwrap","text":"","code":"unwrap(x, cols = NULL, sep = NULL)  flatten(x, cols = NULL, sep = NULL)"},{"path":"https://batchtools.mlr-org.com/dev/reference/unwrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unwrap Nested Data Frames — unwrap","text":"x [data.frame | data.table] Data frame flatten. cols [character] Columns consider operation. set NULL (default), operate columns type “list”. sep [character(1)] NULL (default), column names additional columns re-use names nested list/data.frame. may lead name clashes. provide sep, variable column name constructed “[column name x][sep][inner name]”.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/unwrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unwrap Nested Data Frames — unwrap","text":"[data.table].","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/unwrap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Unwrap Nested Data Frames — unwrap","text":"name clash function flatten package purrr. function flatten discouraged use reason favor unwrap.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/unwrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unwrap Nested Data Frames — unwrap","text":"","code":"x = data.table::data.table(   id = 1:3,   values = list(list(a = 1, b = 3), list(a = 2, b = 2), list(a = 3)) ) unwrap(x) #>       id     a     b #>    <int> <num> <num> #> 1:     1     1     3 #> 2:     2     2     2 #> 3:     3     3    NA unwrap(x, sep = \".\") #>       id values.a values.b #>    <int>    <num>    <num> #> 1:     1        1        3 #> 2:     2        2        2 #> 3:     3        3       NA"},{"path":"https://batchtools.mlr-org.com/dev/reference/waitForJobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Wait for Termination of Jobs — waitForJobs","title":"Wait for Termination of Jobs — waitForJobs","text":"function simply waits jobs terminated.","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/waitForJobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wait for Termination of Jobs — waitForJobs","text":"","code":"waitForJobs(   ids = NULL,   sleep = NULL,   timeout = 604800,   expire.after = NULL,   stop.on.error = FALSE,   stop.on.expire = FALSE,   reg = getDefaultRegistry() )"},{"path":"https://batchtools.mlr-org.com/dev/reference/waitForJobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wait for Termination of Jobs — waitForJobs","text":"ids [data.frame integer] data.frame (data.table) column named “job.id”. Alternatively, may also pass vector integerish job ids. set, defaults return value findSubmitted. Invalid ids ignored. sleep [function() | numeric(1)] Parameter control duration sleep queries. can pass absolute numeric value seconds function() returns number seconds sleep -th iteration. provided (NULL), tries read value (number/function) configuration file (stored reg$sleep) defaults function exponential backoff 5 120 seconds. timeout [numeric(1)] waiting timeout seconds, show message return FALSE. argument may required systems , e.g., expired jobs jobs hold problematic detect. want timeout, set Inf. Default 604800 (one week). expire.[integer(1)] Jobs count “expired” found system communicated back results (error message). frequently happens managed system scheduler kills job job hit walltime request memory reserved. hand, network file systems often require several seconds new files found, can lead false positives detection heuristic. waitForJobs treats jobs expired detected system expire.iterations. provided (NULL), tries read value configuration file (stored reg$expire.), finally defaults 3. stop..error [logical(1)] Immediately cancel job terminates error? Default FALSE. stop..expire [logical(1)] Immediately cancel jobs detected expired? Default FALSE. Expired jobs ignored remainder waitForJobs(). reg [Registry] Registry. explicitly passed, uses default registry (see setDefaultRegistry).","code":""},{"path":"https://batchtools.mlr-org.com/dev/reference/waitForJobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wait for Termination of Jobs — waitForJobs","text":"[logical(1)]. Returns TRUE jobs terminated   successfully FALSE either timeout reached least   one job terminated exception expired.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0917","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.17","title":"batchtools 0.9.17","text":"CRAN release: 2023-04-20 Fixed bug finalizer ClusterFunctionsMulticore.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0916","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.16","title":"batchtools 0.9.16","text":"CRAN release: 2023-02-03 Fixed bug addExperiments() combination combination method \"bind\" repls > 1 experiments duplicated. addExperiments() now also accepts vector replications (instead single scalar value) argument repls. Improved handling jobs ClusterFunctionsSlurm. Fixed bug waitForJobs() Fixed assertions.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0915","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.15","title":"batchtools 0.9.15","text":"CRAN release: 2021-01-11 Maintenance update.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0914","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.14","title":"batchtools 0.9.14","text":"CRAN release: 2020-10-21 batchMap() now supports unnamed .args. Exports now assigned delayedAssign(). Fix option LSF template.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0913","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.13","title":"batchtools 0.9.13","text":"CRAN release: 2020-03-19 Maintenance release R-4.0.0.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0912","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.12","title":"batchtools 0.9.12","text":"CRAN release: 2020-01-10 Moved data.table Depends Imports. User scripts might need explicitly attach data.table via library() now. Fixes ClusterFunctionsMulticore. Removed workaround system2() R-devel (released R-4.0.0). New configuration option compress select compression algorithm (passed saveRDS()).","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0911","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.11","title":"batchtools 0.9.11","text":"CRAN release: 2018-08-16 Removed deprecated function chunkIds(). New default argument fs.timeout cluster function constructor 0 (NA ). Fixed unit test OSX. Improved stability documentation. Fixed memory usage calculation.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-0910","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.10","title":"batchtools 0.9.10","text":"CRAN release: 2018-05-19 Exported functions findConfFile() findTemplateFile(). Dropped support providing template file directly string. valid file now always required. Fixed writing TMPDIR instead R session’s temporary directory.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-099","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.9","title":"batchtools 0.9.9","text":"CRAN release: 2018-05-14 RDS files explicitly stored version 2 ensure backward compatibility R versions prior 3.5.0. Package fs now used internally file system operations. Support per-site configuration files templates set system administrators. print getStatus() now includes time stamp. chunk() now optionally shuffles ids chunking. Support setting per-job resources submitJobs(). Example templates now include resources blas.threads omp.threads. bug fixes regarding read-registries.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-098","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.8","title":"batchtools 0.9.8","text":"CRAN release: 2017-12-15 Renamed column “memory” status table “mem.used” avoid name clashes resource specification. Exported function assertRegistry(). New function unwrap() alias flatten(). latter causes name clash package purrr deprecated future version. Registries now contain unique hash updated time registry altered. Can utilized invalidate caches, e.g. cache knitr.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-097","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.7","title":"batchtools 0.9.7","text":"CRAN release: 2017-11-15 Added workaround test compatible testthat v2.0.0. Better customizable handling expired jobs waitForJobs(). Package foreach now supported nested parallelization alternative parallelMap. Depreciated argument flatten removed. New helper function flatten() manually unnest/unwrap lists data frames. Removed functions getProblemIds() getAlgorithmIds(). Instead, can just access reg$problems reg$algorithms, respectively. number maximum concurrent jobs can now also controlled via setting resources. Internal data base changes speed operations. Old registries updated first load loadRegistry(). Fixed bug sleep mechanism queries working. Fixed bug submit errors SLURM TORQUE detected temporary.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-096","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.6","title":"batchtools 0.9.6","text":"CRAN release: 2017-09-06 Fixed bug wrong problem retrieved cache. triggered chunked jobs combination ExperimentRegistry.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-095","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.5","title":"batchtools 0.9.5","text":"CRAN release: 2017-08-18 Added missing routine upgrade registries created batchtools prior v0.9.3. Fixed bug registry synced jobs failed initialization (#135). sleep duration waitForJobs() submitJobs() can now set via configuration file. new heuristic try detect registry altered simultaneously running R session. detected, registry current session set read-state. waitForJobs() reworked allow control heuristic detect expired jobs. Jobs treated expired submitted detected system expire.iterations (default 3 iterations, 1 iteration). New argument writeable loadRegistry() allow loading registries explicitly read-. Removed argument update.paths loadRegistry(). Paths always updated, registry file system remains unchanged unless loaded read-write mode. ClusterFunctionsSlurm now come experimental nodename argument. set, communication master handled via SSH effectively allows submit jobs local machine instead head node. Note mounting file system (e.g., via SSHFS) mandatory.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-094","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.4","title":"batchtools 0.9.4","text":"CRAN release: 2017-08-07 Fixed handling file.dir special chars like whitespace. backward slashes now converted forward slashes windows. Fixed order arguments findExperiments() (argument ids now first). Removed code upgrade registries created versions prior v0.9.0 (first CRAN release). addExperiments() now warns design passed data.frame factor columns stringsAsFactors TRUE. Added functions setJobNames() getJobNames() control name jobs batch systems. Templates adapted use job.name instead job.hash naming. Argument flatten getJobResources(), getJobPars() getJobTable() deprecated removed. Future versions functions behave like flatten set FALSE explicitly. Single resources/parameters must extracted manually (tidyr::unnest()).","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-093","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.3","title":"batchtools 0.9.3","text":"CRAN release: 2017-04-21 Running jobs now also included querying status “started”. affects findStarted(), findNotStarted() getStatus(). findExperiments() now performs exact string match (instead matching substrings) patterns specified via prob.name algo.name. substring matching, use prob.pattern algo.pattern, respectively. Removed fill, now always TRUE Introduced flatten control result represented column lists flattened separate columns. Defaults backward-compatible heuristic, similar getJobPars. Improved heuristic lookup template files. Templates shipped package can now used providing just file name (w/o extension). Updated CITATION","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-092","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.2","title":"batchtools 0.9.2","text":"CRAN release: 2017-02-20 Full support array jobs Slurm TORQUE. Array jobs disabled SGE LSF (due missing information output format) re-enable future release. Note variable n.array.jobs removed JobCollection favor new variable array.jobs (logical). findExperiments() now two additional arguments match using regular expressions. possibility prefix string “~” enable regular expression matching removed. New function batchReduce(). New function estimateRuntimes(). New function removeRegistry(). Missing result files now handled consistently, raising exception defaults result available. argument missing.val added reduceResultsList() reduceResultsDataTable() removed loadResult() batchMapResults(). Timestamps now stored sub-second accuracy. Renamed Torque TORQUE. especially affects constructor makeClusterFunctionsTorque now must called via makeClusterFunctionsTORQUE() chunkIds() deprecated. Use chunk(), lpt() binpack() instead. Fixed listing jobs ClusterFunctionsLSF ClusterFunctionsOpenLava (thanks @phaverty). Job hashes now prefixed literal string ‘job’ ensure start letter required SGE systems. Fixed handling NULL results reduceResultsList() Fixed key lookup heuristic join functions. Fixed bug getJobTable() returned difftimes wrong unit (e.g., minutes instead seconds). Deactivated swap allocation ClusterFunctionsDocker. package now patient communicating scheduler file system using timeout-based approach. make package reliable robust heavy load.","code":""},{"path":"https://batchtools.mlr-org.com/dev/news/index.html","id":"batchtools-090","dir":"Changelog","previous_headings":"","what":"batchtools 0.9.0","title":"batchtools 0.9.0","text":"CRAN release: 2016-11-08 Initial CRAN release. See vignette brief comparison BatchJobs/BatchExperiments.","code":""}]
